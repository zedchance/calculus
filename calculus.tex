% Calculus II notes
% Zed Chance

\documentclass{report}

\usepackage{mathtools}

% Cancel slash \cancel
\usepackage[makeroom]{cancel}

% Margin
\usepackage[margin=1in]{geometry}

% TOC links
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linktoc=all,
    linkcolor=black
}

% TOC depth
\setcounter{tocdepth}{1}

% Header customization
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\fancyhead[L]{\leftmark}
\fancyhead[R]{\rightmark}
\fancyfoot[C]{\thepage}
\renewcommand{\headrulewidth}{0pt}

% Graphs
\usepackage{pgf,tikz,pgfplots}
\pgfplotsset{compat=1.15}
\usepackage{mathrsfs}
\usetikzlibrary{arrows}
\definecolor{rvwvcq}{rgb}{0.08235294117647059,0.396078431372549,0.7529411764705882}

\title{Calculus II}
\date{Spring 2020}
\author{Zed Chance}

\begin{document}
\maketitle
\tableofcontents
\newpage

\chapter{Sequences and series}

\section{What is a series?}
    To evaluate series, first find the partial sum:
    \begin{align*}
        \sum_{n=1}^\infty & n \\
        S_n = 1 +  2 & + 3 +\  \cdots \  + n
    \end{align*}
    Find the formula for \(S_n\)
    \[S_n= \frac{n(n+1)}{2}\]
    Take the limit as \(n \rightarrow \infty\)
    \[\lim_{n \rightarrow \infty} \frac{n(n+1)}{2} = \infty\]

\section{Telescoping series}
    These series look like two repeating fractions that end up canceling everything except something from the first term and something from the last. For example:
    \[\sum_{n=1}^{\infty} \Big (\frac{1}{2n+3} - \frac{1}{2n+1}\Big )\]
    First find the partial sum \(S_n\)
    \[S_n = \Big ( \frac{1}{5}-\frac{1}{3}\Big ) + \Big ( \frac{1}{7}-\frac{1}{5}\Big ) + \Big ( \frac{1}{9}-\frac{1}{7}\Big ) + \ \cdots \]
    \[+\ \Big ( \frac{1}{2n+1}-\frac{1}{2n-1}\Big ) + \Big ( \frac{1}{2n+3}-\frac{1}{2n+1}\Big )\]
    Almost all of these fractions will cancel if you see the patern. The only 2 left are:
    \[S_n = - \frac{1}{3} + \frac{1}{2n+3}\]
    Take the limit of this partial sum \(S_n\)
    \[\lim_{n \rightarrow \infty}\big[ - \frac{1}{3} + \frac{1}{2n+3} \big] = - \frac{1}{3}\]

\section{Geometric series}
    Geometric series take the form of:
    \[\sum_{n=1}^\infty ar^{n-1}\]
    The series will converge of \(\big|r\big|< 1\), otherwise it will diverge.
    If the sum does converge, the sum is:
    \[\sum_{n=1}^\infty ar^{n-1} = \frac{a}{1-r}\]
    \subsection{Shortcut}
        If the first power of the sequence is 0 then the first term is \(a\). \(a\) stands for the first term in your series.
        For example:
        \begin{align*}
            \sum_{n=1}^{\infty} \Big ( \frac{2}{3} \Big )^n & = \sum_{n=1}^{\infty} \Big ( \frac{2}{3} \Big )\Big ( \frac{2}{3} \Big )^{n-1} \\
            & = \frac{\frac{2}{3}}{1-\frac{2}{3}}
        \end{align*}
        Another example:
        \begin{align*}
            \sum_{n=2}^{\infty} \frac{e^n}{3^{n+1}} & = \sum_{n=2}^{\infty} \frac{e^n}{3\cdot 3^n} \\
            & = \sum_{n=2}^{\infty} \frac{1}{3} \Big( \frac{e}{3}\Big)^n
        \end{align*}
        The mistake most people make here is thinking that \(a = \frac{1}{3}\). This isn't the case because plugging in \(n=2\) doesn't make the first exponent 0. So split off more \(\frac{e}{3}\)'s to make it in the right form:
        \begin{align*}
            & = \sum_{n=2}^{\infty} \frac{1}{3} \Big( \frac{3}{3} \Big)^2 \Big( \frac{e}{3} \Big) ^{n-2} \\
            & = \sum_{n=2}^{\infty} \frac{e^2}{27} \Big( \frac{e}{3} \Big) ^{n-2}
        \end{align*}
        Now since the first term makes the exponent go to 0. You can tell what \(a\) and \(r\) are now. So:
        \[= \frac{ \frac{e^2}{27} }{1- \frac{e^2}{3}}\]
        So the shortcut here is that you can start with
        \[= \sum_{n=2}^{\infty} \frac{1}{3} \Big( \frac{e}{3}\Big)^n\]
        and simply plug in 2 for \(n\) (the starting point). Since we know that the first term is \(a\) you can jump to the answer:
        \[= \frac{ \frac{e^2}{27} }{1- \frac{e^2}{3}}\]
        
\section{Harmonic}
    Harmonc series are defined as:
    \[\sum_{n=1}^{\infty} \frac{1}{n} = \frac{1}{1} + \frac{1}{2} + \frac{1}{3} +\ \cdots + \frac{1}{n}\]
    Harmonic series are divergent. If a sequence \(\{a_n\}\) is convergent, any subsequence of \(\{a_n\}\) must also be convergent. To show that a sequence \(\{a_n\}\) diverges, it is enough to show that a subsequence diverges.
    \textbf{Note}: If a series converges, then
    \[\sum_{n=1}^{\infty} a_n\]
    \[\lim_{n \rightarrow \infty}^{} a_n = 0\]
    So to show a series diverges, it's enough to show:
    \[\lim_{n \rightarrow \infty} a_n \neq 0\]
    If the limit doesn't equal 0, or \(DNE\), the series \(\{a_n\}\) diverges.
    Remember! The limit equaling 0 does \textbf{NOT} necessarily mean convergence!
    \subsection{Example}
        \begin{align*}
            \sum_{n=1}^{\infty}& \frac{2n^2-1}{3n^2-1} \\
            \lim_{n \rightarrow \infty}& \frac{2n^2-1}{3n^2-1} \neq 0
        \end{align*}
        Diverges because the limit equals 0!

\section{P-Series}
    \[\sum_{n=1}^\infty \frac{1}{n^P}\]
    When \(P < 1\) the series will diverge. 
    \[\lim_{n \rightarrow \infty} \frac{1}{n^P}\]
    When \(P > 1\) the series will converge (can be shown with the integral test).
    \subsection{Example}
        \[\sum_{n=1}^{\infty} \frac{1}{n^2}\]
        Here we can see that \(P = 2\) (greater than 1), so the series must converge.
    \subsection{Example}
        \[\sum_{n=1}^\infty \frac{1}{\sqrt[3]{n}}\]
        Here we can see that \(P = \frac{1}{3}\) (less than 1), so the series diverges.
    \subsection{Example}
        \[\sum_{n=1}^\infty n^{-\pi} = \sum_{n=1}^\infty \frac{1}{n^\pi}\]
        Since \(P = \pi\) (greater than 1) the series must converge.

\section{Properties of convergent series}
    1. You can always pull a constant out in front of the series
    \[\sum_{n=1}^{\infty} C a_n = C \sum_{n=1}^{\infty} a_n\]
    2. You can split sequences on sums or differences
    \[\sum_{n=1}^{\infty} (a_n \pm b_n) = \sum_{n=1}^{\infty} a_n \pm \sum_{n=1}^{\infty} b_n\]
    \subsection{Example}
        \begin{align*}
            \sum_{n=1}^{\infty} \Big ( \frac{2^n-5^n}{3^n}\Big ) & =\sum_{n=1}^{\infty} \Big ( \frac{2^n}{3^n} - \frac{5^n}{3^n}\Big ) \\
            & =\sum_{n=1}^{\infty} \frac{2^n}{3^n} - \sum_{n=1}^{\infty} \frac{5^n}{3^n}
        \end{align*}
        If we split this sequence into parts, each part much be convergent for the entire sequence to be convergent! If any single part is divergent then the entire thing is divergent.
        \[=\sum_{n=1}^{\infty} \Big (\frac{2}{3}\Big )^n - \sum_{n=1}^{\infty} \Big (\frac{5}{3}\Big )^n\]
        In this form we can evaluate them as geometric series. Automatically we know this is divergent because the rightmost fraction's \(r\) is greater than 1. Since a subsequence of the original diverges, the original does too.

\section{Integral test}
    For \(f(n) = a_n\), if \(f(n)\) is continous, positive, and decreasing, then we can use the integral to show convergence/divergence of our series. 
    So:
    \[\sum_{n=1}^\infty \text{ and } \int_1^\infty f(x)\ dx\]
    will have the same result (either converge or diverge).
    \begin{itemize}
        \item This can tell you convergence/divergence, but does not necessarily give the sum of the series.
        \item Convergence is \textbf{not} affected by the addition or subtraction of a \textbf{finite} number of terms from our series. 
    \end{itemize}
    We can judge the convergence of \(\sum_{n=1}^\infty a_n\) with:
    \[\sum_{n=1}^\infty a_n \text{ or } \int_1^\infty f(x)\ dx\]
    But to do the integral test, we can start the integral at \(N\), the sum of our integral will not be the sum of the series, but we can at least tell if it converges/diverges.
    \[\int_N^\infty f(x)\ dx\]
    \subsection{Example}
        \[\sum_{n=1}^\infty \frac{1}{n^2+1}\]
        First thing first, you should check the divergence by taking the limit. The limit here equals 0, so it fails the divergence test. (It may be divergent some other way, but we don't know. It may be convergent, but we don't know). It's not telescoping, its not factorable, so lets try the integral test.
        \[f(x) = \frac{1}{x^2+1}\]
        This should act as an upper bound for our sequence provided its always positive, continuous, and decreasing on it's interval \([1, \infty)\). If it meets these requirements then we can do the integral test:
        \[\int_1^\infty \frac{1}{x^2+1} dx\]
        This is an improper integral:
        \begin{align*}
            \lim_{b \rightarrow \infty} \int_1^b \frac{1}{x^2+1} dx & = \lim_{b \rightarrow \infty} \Big[ \tan^{-1}x \Big]_1^b \\
            & = \lim_{b \rightarrow \infty} \Big[ \tan^{-1}b - \tan^{-1}1 \Big] \\
            & = \frac{\pi}{2} - \frac{\pi}{4} \\
            & = \frac{\pi}{4}
        \end{align*}
        Since we got a number, that shows that the series must converge! \textbf{Our answer from the integral is not necessarily the sum of the series!}
    
    \subsection{Example}
        \[\sum_{n=1}^\infty \frac{3}{2n-1}\]
        Try the divergence test first. The limit is 0 so it doesn't automatically diverge. 
        The integral test:
        \[f(x) = \frac{3}{2x-1}\]
        It isn't always positive, but it is on our interval \([1, \infty)\). It is continuous on our interval and it is also decreasing, so lets try the integral test.
        \begin{align*}
            \int_1^\infty \frac{3}{2x-1} & = \lim_{b \rightarrow \infty} \int_1^b \frac{3}{2x-1} \\
            && u = 2x-1 \\ && du = 2dx \\
            & = \lim_{b \rightarrow \infty} \frac{3}{2} \int \frac{1}{u} du \\
            & = \lim_{b \rightarrow \infty} \frac{3}{2} \ln \ \big[2x-1\big]_1^b \\
            & = \frac{3}{2} \lim_{b \rightarrow \infty} \big[ \ln(2b-1) - \ln(2-1) \big] \\
            & = \infty
        \end{align*}
        Since the limit evaluates to \(\infty\) the integral diverges. So the series also diverges.
    
    \subsection{Example}
        \begin{align*}
            \sum_{n=1}^\infty \frac{\ln n}{n} \\
            f(x) = \frac{\ln x}{x}
        \end{align*}
        The function is positive and continuous. To show decreasing show that \(f'(x) < 0\):
        \begin{align*}
            f'(x) & = \frac{1 - \ln x}{x^2} \\
            1 & \leq \ln x \\
            e & \leq x
        \end{align*}
        Choose a interval where \(f(x)\) will be decreasing. \(f(x)\) will certainly be decreasing on the interval \([3, \infty)\).
        So:
        \begin{align*}
            \int_3^\infty \frac{\ln x}{x} & = \lim_{b \rightarrow \infty} \int_3^b \frac{\ln x}{x} dx \\
            && u = \ln x \\
            && du = \frac{1}{x} dx \\
            & = \lim_{b \rightarrow \infty} \int_3^b u\ du \\
            & = \lim_{b \rightarrow \infty} \big[ \frac{1}{2} (\ln x)^2\big]_3^b \\
            & = \lim_{b \rightarrow \infty} \big[ \frac{1}{2} (\ln b)^2 - \frac{1}{2} (\ln 3)^2 \big] \\
            & = \infty
        \end{align*}
        Therefore, the integral diverges. So the series also diverges.

    \subsection{Example}
        \[\sum_{n=1}^\infty \frac{e^\frac{1}{n}}{n^2}\]
        First do the divergence test, the limit is 0 so it doesn't immediately diverge. Its not a geometric series. Its also not a P-series. Let's try the integral test.
        \[f(x) = \frac{e^\frac{1}{x}}{x^2}\]
        The function must be positive, continuous, and decreasing on the interval.
        The function is positive. Its only discontinuous at 0 and thats not in our interval.
        To show decreasing make sure \(f'(x) < 0\) (alternatively you could show that \(a_{n-1} < a_n\)):
        \begin{align*}
            f'(x) & = \frac{-e^\frac{1}{x}-2xe^\frac{1}{x}}{x^4} \\
            & = \frac{-e^\frac{1}{x}(1+2x)}{x^4} \\
        \end{align*}
        This is negative on our interval \([1, \infty)\).
        So lets do the integral test:
        \begin{align*}
            \int_1^\infty \frac{e^\frac{1}{x}}{x^2} dx & = \lim_{b \rightarrow \infty} \int_1^b \frac{e^\frac{1}{x}}{x^2} dx \\
            && u & = \frac{1}{x} \\
            && du & = - \frac{1}{x^2} dx \\
            & = - \lim_{b \rightarrow \infty} \int_1^b e^u du \\
            & = - \lim_{b \rightarrow \infty} \big[ e^\frac{1}{x}\big]_1^b \\
            & = - \lim_{b \rightarrow \infty} \big[ e^\frac{1}{b} - e^1 \big] \\
            & = - [1 - e] \\
            & = e - 1
        \end{align*}
        Therefore since the integral converges, the series must converge also.

\section{Comparison tests}
    Idea: Compare one series to another with a known convergence/divergence (geometric, harmonic, p-series, etc). 
    Suppose we have two series \(\sum a_n\) and \(\sum b_n\) \textbf{with positive terms}:
    \begin{itemize}
        \item If \(a_b < b_n\) for all \(n\), and \(\sum b_n\) converges, then \(\sum a_n\) also converges.
        \item If \(a_b > b_n\) for all \(n\), and \(\sum b_n\) diverges, then \(\sum a_n\) also diverges.
    \end{itemize}
    If you show divergence for \(b_n\) when \(a_n < b_n\), it proves nothing.
    The upper series diverges up to infinity and that tells us nothing about the lower series.
    It may diverge or converge. So make sure to show the correct comparison.
    (The same useless comparison is showing convergence for \(b_n\) when \(a_n > b_n\)).

    \subsection{Example}
        \[\sum_{n=1}^\infty \frac{1}{n^2+2}\]
        First check if it fails divergence test, look for other known series, see if integral test could work (it would), but theres a better way. Consider this comparison:
        \[0 \leq \frac{1}{n^2+2} \leq \frac{1}{n^2}\]
        If we're trying to show convergence, we need this to be less than something we know convergence for.
        So lets show convergence of \(\frac{1}{n^2}\):
        \[\sum_{n=1}^\infty \frac{1}{n^2}\]
        This is a P-series with \(p=2\), and since our \(p >1\) it means the series converges. This means by the comparison test that the original problem also converges.

    \subsection{Example}
        \[\sum_{n=1}^\infty \frac{1}{3+2^n}\]
        All the terms are positive on the interval, consider this comparison:
        \[0 \leq \frac{1}{3+2^n} \leq \frac{1}{2^n}\]
        So try to determine convergence of the rightmost fraction:
        \begin{align*}
            \sum_{n=1}^\infty \frac{1}{2^n} & = \sum_{n=1}^\infty \Big( \frac{1}{2} \Big)^n \\
            & = \sum_{n=1}^\infty \Big( \frac{1}{2} \Big) \Big( \frac{1}{2}\Big)^{n-1}
        \end{align*}
        This is a geometric sum with \(a = \frac{1}{2}\) and \(r = \frac{1}{2}\), therefore since \(r < 1\) this will converge. So by the comparison test the original problem also converges.

    \subsection{Example}
        \[\sum_{n=3}^\infty \frac{3^n}{2^n-4}\]
        All the terms on the interval are positive, so lets try a comparison:
        \[\frac{3^n}{2^n - 4} \geq \frac{3^n}{2^n}\]
        We're trying to show divergence of the rightmost fraction, and that will show that the original also diverges.
        \begin{align*}
            \sum_{n=3}^\infty \frac{3^n}{2^n} & = \sum_{n=3}^\infty \Big( \frac{3}{2} \Big)^n \\
            & = \sum_{n=3}^\infty \Big( \frac{3}{2} \Big)^3 \Big( \frac{3}{2} \Big)^{n-3}
        \end{align*}
        Since this is a geometric and our \(r > 1\), it diverges. Therefore the original problem diverges.

    \subsection{Example}
        \[\sum_{n=1}^\infty \frac{1}{\sqrt{n} + 1}\]
        Consider this comparison:
        \[0 \leq \frac{1}{\sqrt{n}+1} \leq \frac{1}{\sqrt{n}}\]
        This is a P-series with \(p = \frac{1}{2}\) (less than 1). This means it diverges. This shows nothing about the original problem!
        When you can't use a comparison like this, you can use the limit comparison test.

\section{Limit comparison test}
    Idea: If \(\sum a_n\) and \(\sum b_n\) have \textbf{positive terms}, and this limit exists:
    \[\lim_{n \rightarrow \infty} \frac{a_n}{b_n}\]
    then that means that both terms are so close together their behavior matches. That means that both series either converge or diverge.
    If it goes to infinity then the terms must difference enough that one or both of them diverges. 

    \subsection{Proof}
        Suppose this limit exists:
        \[\lim_{n \rightarrow \infty} \frac{a_n}{b_n} = L\]
        Then by definition:
        \[\Big| \frac{a_b}{b_n} - L \Big| < \epsilon\]
        So:
        \begin{align*}
            -\epsilon L <  &\frac{a_b}{b_n} - L  < \epsilon L \\
            L-\epsilon L <  &\frac{a_b}{b_n} < L + \epsilon L \\
            (1-\epsilon)L \cdot b_n < &a_n < (1+ \epsilon)L \cdot b_n
        \end{align*}
        \((1+ \epsilon)L\) is just a constant (doesn't affect the convergence/divergence of the series), so if \(b_n\) converges \(a_n\) is less than that so it also converges.
        If \(b_n\) diverges, then \(a_n\) is greater than that so it also diverges.

    \subsection{Example}
        So to take a look again at Example 4 above:
        \[\sum_{n=1}^\infty \frac{1}{\sqrt{n} + 1}\]
        Lets try the limit comparison test where:
        \[\lim_{n \rightarrow \infty} \frac{a_n}{b_n}\]
        and
        \[b_n = \frac{1}{\sqrt{n}}\]
        So:
        \begin{align*}
            \lim_{n \rightarrow \infty} \frac{\frac{1}{\sqrt{n} + 1}}{\frac{1}{\sqrt{n}}} & = \lim_{n \rightarrow \infty} \frac{1}{\sqrt{n} + 1} \cdot \frac{\sqrt{n}}{1} \\
            & = \lim_{n \rightarrow \infty} \frac{\sqrt{n}}{\sqrt{n} + 1} \\
            & = \lim_{n \rightarrow \infty} \frac{1}{1 + \frac{1}{\sqrt{n}}} \\
            & = 1
        \end{align*}
        Since our limit exists, \(a_n\) and \(b_n\) are so close together, that if one converges the other must also. If one diverges the other must also. Just because the limit exists it doesn't mean they converge! They will just have the same result. 
        Now we know that \(b_n\) diverges (p-series with \(p < 1\)), it means the \(a_n\) does also!

    \subsection{Example}
        \[\sum_{n=1}^\infty \frac{2n^2+n}{\sqrt{4n^7+3}}\]
        Lets choose a \(b_n\) that we know convergence/divergence. Start by trying a \(b_n\) that models the end behavior of \(a_n\):
        \begin{align*}
            \sum_{n=1}^\infty \frac{2n^2}{\sqrt{4n^7}} & = \sum_{n=1}^\infty \frac{1}{n^{3/2}}
        \end{align*}
        This is a P-series with a \(p = \frac{3}{2}\), since \(p > 1\) it converges!
        Limit comparison test:
        \begin{align*}
            \lim_{n \rightarrow \infty} \frac{a_n}{b_n} & = \lim_{n \rightarrow \infty} \frac{\frac{2n^2+n}{\sqrt{4n^7+3}}}{\frac{1}{n^{3/2}}} \\
            & = \lim_{n \rightarrow \infty} \frac{2n^2+n}{\sqrt{4n^7+3}} \cdot n^{3/2} \\
            & = \lim_{n \rightarrow \infty} \frac{2n^{7/2} + n^{5/2}}{\sqrt{4n^7+3}} \\
            & = \lim_{n \rightarrow \infty} \frac{2 + \frac{1}{n}}{\sqrt{4 + \frac{3}{n^7}}} \\
            & = 1
        \end{align*}
        Since we know the limit exists, and we know that \(b_n\) converges, \(a_n\) must converge also!

    \subsection{Example}
    \[\sum_{n=1}^\infty \frac{\sqrt{n} + \ln n}{n^2 + 1}\]
    Lets use the limit comparison test, and compare to \(b_n\) of:
    \begin{align*}
        b_n & = \sum_{n=1}^\infty \frac{\sqrt{n}}{n^2} \\
        & = \sum_{n=1}^\infty \frac{1}{n^{3/2}}
    \end{align*}
    This is a P-series with \(p = \frac{3}{2}\), so \(b_n\) converges (\(p > 1\)).
    Limit comparison test:
    \begin{align*}
        \lim_{n \rightarrow \infty} \frac{\sqrt{n} + \ln n}{n^2 + 1} \cdot n^{3/2} & = \lim_{n \rightarrow \infty} \frac{n^2 + n^{3/2} \ln n}{n^2 + 1} \\
        & = \lim_{n \rightarrow \infty} \frac{1 + \frac{\ln n}{n^{1/2}}}{1 + \frac{1}{n^{2}}} \\
        && \text{Aside:} \\
        && = \lim_{n \rightarrow \infty} \frac{\ln n}{n^{1/2}} \\
        && \text{Use L'Hospitals} \\ 
        && = \lim_{n \rightarrow \infty} \frac{\frac{1}{n}}{\frac{1}{2\sqrt{n}}} \\
        && = \lim_{n \rightarrow \infty} \frac{2\sqrt{n}}{n} \\
        && \text{Use L'Hospitals} \\
        && = \lim_{n \rightarrow \infty} \frac{2}{\sqrt{n}} \\
        && = 0 \\
        & = \lim_{n \rightarrow \infty} \frac{1 + 0}{1 + 0} \\
        & = 1
    \end{align*}
    So since the series \(b_n\) converges, the series \(a_n\) also converges.

\section{Alternating series test}
    Simply a series where sequential terms alternate signs (positive, negative...). 
    \[\sum_{n = 1}^{\infty} \frac{(-1)^{n-1}}{n} = 1 - \frac{1}{2} + \frac{1}{3} - \frac{1}{4} + \cdots \]
    All of these series can be written as:
    \[\sum_{n = 1}^{\infty}  (-1)^{n-1} \cdot a_n\]
    \[\sum_{n = 1}^{\infty} (-1)^{n-1} \cdot \frac{1}{n}\]
    This is basically an alternating Harmonic series.\\
    \\
    The test goes like this:
    \begin{itemize}
        \item Verify that it is alternating
        \item Look at the limit of sequence of the positive terms \(a_n\)
        \item If the sequence is also decreasing, then its convergent. (It just needs to pass the divergence test as far as the sequence of positive terms is concerned.)
    \end{itemize}
    Ultimately if the series converges it is bracketing the value that it is trending to.
    \subsection{Example}
        \[\sum_{n = 1}^{\infty}  \frac{(-1)^n \cdot n^2}{(n+1)!} = -\frac{1}{2!} + \frac{4}{3!} - \frac{9}{4!} + \frac{16}{5!} - \cdots \]
        This is basically the same as:
        \[\sum_{n = 1}^{\infty} (-1)^n \cdot a_n \]
        So heres the test:
        \[\sum_{n = 1}^{\infty} (-1)^{n-1} \cdot a_n \]
        If it weren't for the \((-1)^{n-1}\) then all of the \(a_n\) terms would be positive. So you can say that \(a_n > 0\).
        So if \(a_{n+1} \leq a_n\) for all \(n\) then it shows that the values are decreasing. And:
        \[\lim_{n \to \infty} a_n  = 0\]
        The series converges because \(a_n\) is decreasing.
    
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} \frac{(-1)^{n-1}}{n} = \sum_{n = 1}^{\infty} (-1)^{n-1} \cdot \frac{1}{n}\]
        Break off the alternating factor \((-1)^{n-1}\) and it reveals that \(a_n = \frac{1}{n}\). 
        First check the divergence test on the positive terms of \(a_n\):
        \[\lim_{n \to \infty} \frac{1}{n} = 0\]
        Show that the terms are decreasing (\(a_{n+1} \leq a_n\)):
        \[a_{n+1} = \frac{1}{n+1} \leq \frac{1}{n} = a_n\]
        \[a_{n+1} \leq a_n\]
        Therefore by the alternating series test, because it passes the divergence test and decreasing, the series converges.
        An interesting point about this example is that the positive terms of \(a_n\) end up being the harmonic series (which diverges), but since it is alternating it ends up converging.
        
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} (-1)^n \cdot \frac{2n}{4n-1} \]
        Since the alternating factor is broken off of the problem for us its easy to see that:
        \[a_n = \frac{2n}{4n-1}\]
        First try the divergence test:
        \[\lim_{n \to \infty} \frac{2n}{4n-1} = \frac{1}{2}\]
        Since the limit exists, it fails the divergence test, thus it diverges.
        
    \subsection{Example}
        \[\sum_{n=2}^{\infty} \frac{(-1)^{n-1} \sqrt{n+1}}{n-1}\]
        Isolate \(a_n\):
        \[a_n = \frac{\sqrt{n+1}}{n-1}\]
        Check the divrgence test:
        \[\lim_{n \to \infty} \frac{\sqrt{n+1}}{n-1} = 0\]
        Now to show decreasing lets take the derivative:
        \[f(x) = \frac{\sqrt{x+1}}{x-1}\]
        \[f'(x) = \frac{-x-3}{2\sqrt{x+1}(x-1)^2}\]
        Since \(f'(x) < 0\) it shows that \(a_n\) is decreasing. So by the alternating series test, the given series converges.
    
    \subsection{Finding error on our series}
        If \(\sum a_n\) converges, then it will have a sum \(S\). The limit of the partial sums = \(S\).
        \[\lim_{n \to \infty}  S_n = S\]
        If thats true, then the difference between these should be 0.
        \[\lim_{n \to \infty} (S - S_n) = 0\]
        If \(n\) doesn't actually approach \(\infty\), then there will actually be a difference between the two, we call this the error \(R_n\).
        \[R_n = S - S_n\]
        This idea is for all series.\\
        \\
        The following is for \textbf{alternating series only}:
        \[|R_n| = |S - S_n| \leq a_{n+1}\]
        The whole sum \(S\) is:
        \[S=a_1 - a_2 + a_3 - \cdots - a_n + a_{n+1} - a_{n+2} + \cdots\]
        Whereas the the partial sum \(S_n\) stops at \(a_n\). So the error \(R_n\) is less than or equal to the next term \(a_{n+1}\).
        To visualize:
        \[\overbrace{\underbrace{a_1 - a_2 + a_3 - \cdots - a_n}_{S_n} + \underbrace{a_{n+1} - a_{n+2} + \cdots}_{S - S_n = R_n}}^{S} \]
        This finding error test only works for convergent alternating series.
        
    \subsection{Example}
        \[\sum_{n = 0}^{\infty} \frac{(-1)^n}{n!}\]
        Here we can see that:
        \[a_n = \frac{1}{n!}\]
        Check the limit of \(a_n\):
        \[\lim_{n \to \infty} \frac{1}{n!} \]
        Now we need to show that \(a_n\) is decreasing:
        \[a_{n+1} \leq a_n\]
        \[\frac{1}{(n+1)!} \leq \frac{1}{n!}\]
        By the alternating series test, the given series must converge. To show error:
        \[|R_n| = |S - S_n| \leq a_{n+1}\]
        \[|R_n| \leq \frac{1}{(n+1)!}\]
        Finding error works by starting with how accurate you want to be, then use \(R_n\) to determine how many terms are needed to be that accurate. For example:
        \[|R_n| < 0.0005\]
        \[|R_n| \leq \frac{1}{(n+1)!} < 0.0005\]
        Then solve for \(n\) (not explicitly):
        \[(n+1)! > \frac{1}{0.0005}\]
        \[(n+1)! > 2000\]
        Start by trying numbers of \(n\) that will be bigger than 2000. So the first term that satisfies the inequality is \(n = 6\)
        \[S_6 = 1 - 1 + \frac{1}{2} - \frac{1}{6} + \frac{1}{24} - \frac{1}{120}+ \frac{1}{720}\]
        \[S_6 = 0.368\]
        This is not equal to \(S\), however it is within 0.0005 \% error.

\section{Absolute convergence}
    For \(\sum a_n\), if \(\sum |a_n|\) is convergent, then we can say that the given series is \textbf{absolutely convergent}. This is the strongest convergence because
    if the series \(a_n\) is convergent but \(|a_n|\) is divergent it is called \textbf{conditionally convergent}. So if a series if absolutely convergent
    you know that the series is also convergent.
    So for instance:
    \[\sum_{n = 1}^{\infty} \frac{\sin 2n}{n^2}\]
    isn't always positive, isn't always decreasing, and isn't alternating (theres a series of terms negative and then a series positive).
    This is a series we'd want to use absolute convergence on.
    \[\sum_{n = 1}^{\infty} \left| \frac{\sin 2n}{n^2} \right|\]
    Remember:
    \[-1 \leq \sin x \leq 1\]
    \[| \sin x | \leq 1\]
    \[| \sin 2x | \leq 1\]
    So:
    \[\left| \frac{\sin 2n}{n^2} \right| \leq \frac{1}{n^2}\] 
    So lets try to evaluate this series to show absolute convergence:
    \[\sum_{n = 1}^{\infty} \frac{1}{n^2} \]
    This is a P-series with \(P = 2\) which means it converges because \(P > 1\).
    By the comparison test that means that the series \(|a_n|\) converges also.
    Since the series \(|a_n|\) converges, that means that the original series \(a_n\) absolutely converges (which means it also converges).
    
    
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} \frac{(-1)^{n-1}}{n^2}\]
        Start by trying the series with the \(|a_n|\).
        \[\sum_{n = 1}^{\infty} \left| \frac{(-1)^{n-1}}{n^2} \right| = \sum_{n = 1}^{\infty} \frac{1}{n^2} \]
        This means that it isn't an alternating series anymore. So now it can be seen as a P-series with \(P = 2\). This means that \(|a_n|\) converges.
        This means that the original series \(a_n\) absolutely converges.
    
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} \frac{(-1)^{n-1}}{n}\]
        This is the alternating harmonic series which is convergent (shown above). So lets try to show that \(|a_n|\) converges to see if it absolutely converges.
        \[\sum_{n = 1}^{\infty} \left| \frac{(-1)^{n-1}}{n} \right| = \sum_{n = 1}^{\infty} \frac{1}{n} \]
        This is a harmonic series which diverges. So this means that the original series \(a_n\) is not absolutely convergent, despite it converging! 
        This means that the series \(a_n\) is conditionally convergent.

\newpage
\section{Ratio test}
    If you can make a ratio between the next term \(a_{n+1}\) and \(a_n\) and the limit of the ratio is less than one:
    \[\lim_{n \to \infty} \frac{a_{n+1}}{a_n} < 1 \]
    this tells us that our series \(\sum a_n\) is absolutely convergent.
    If the ratio is greater than one:
    \[\lim_{n \to \infty} \frac{a_{n+1}}{a_n} > 1 \]
    this means that the series \(\sum a_n\) is divergent.
    If the ratio is equal to one:
    \[\lim_{n \to \infty} \frac{a_{n+1}}{a_n} = 1 \]
    this means that the test is inconclusive, which means you'll need to try a different technique.
    
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} \frac{(-1)^{n-1} \cdot n^1 + 1}{2^n} \]
        This is alternating, and decreasing, so you could use the alternating series test to show its convergence/divergence.
        But lets try the ratio test:
        \begin{align*}
            \lim_{n \to \infty} \frac{a_{n+1}}{a_n} & = \lim_{n \to \infty} \left| \frac{\frac{(-1)^n \cdot (n+1)^2 + 1}{2^{n+1}}}{\frac{(-1)^{n-1} \cdot n^1 + 1}{2^n}} \right| \\
            & = \lim_{n \to \infty} \frac{(n+1)^2 + 1}{2^{n+1}} \cdot \frac{2^n}{n^2+1} \\
            & = \lim_{n \to \infty} \frac{n^2+2n+2}{2n^2+2} \\
            & = \frac{1}{2}
        \end{align*}
        So by the ratio test, since the limit of the ratio is less than 1, it tells us that the original series is absolutely convergent.
        Since the series is absolutely convergent, it is also convergent.
    
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} \frac{n!}{n^n} \]
        Lets try the ratio test:
        \begin{align*}
            \lim_{n \to \infty} \left| \frac{\frac{(n+1)!}{(n+1)^{n+1}}}{\frac{n!}{n^n}} \right| & = \lim_{n \to \infty} \frac{(n+1)!}{(n+1)^{n+1}} \cdot \frac{n^n}{n!} \\
            & = \lim_{n \to \infty} \frac{(n+1) \cdot n!}{(n+1)^{n} \cdot (n+1)} \cdot \frac{n^n}{n!} \\
            & = \lim_{n \to \infty} \frac{n^n}{(n+1)^n} \\
            & = \lim_{n \to \infty} \left( \frac{n}{n+1} \right)^n \text{(indeterminate form)}\\
            & = \lim_{n \to \infty} \left( \frac{n+1}{n}\right)^{-n} \\
            & = \lim_{n \to \infty} \frac{1}{\left( \frac{n+1}{n}\right)^{n}} \\
            && &\text{Aside:} \\
            && &\lim_{n \to \infty} \left( \frac{n+1}{n}\right)^{n} \\
            && &= e^{\lim \left( \frac{n+1}{n}\right)^{n}} \\
            && &= e^{\lim n \ln \left( \frac{n+1}{n}\right)} \\
            && &= e^{\lim \frac{\ln \left( \frac{n+1}{n}\right)}{\frac{1}{n}}} \\
            && &= e^{\lim \frac{1}{1+\frac{1}{n}}} \\
            && &= e \\
            \lim_{n \to \infty} \frac{1}{\left( \frac{n+1}{n}\right)^{n}} &= \frac{1}{e}
        \end{align*}
       So by the ratio test, the given series is absolutely convergent.
    
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} \frac{(-5)^{n-1}}{n^2 \cdot 3^n} \]
        First lets setup the ratio test:
        \begin{align*}
            \lim_{n \to \infty} \left| \frac{\frac{(-5)^n}{(n+1)^2 \cdot 3^{n-1}}}{\frac{(-5)^{n-1}}{n^2 \cdot 3^n}} \right|
            &= \lim_{n \to \infty} \frac{5^n}{(n+1)^2 \cdot 3^{n+1}} \cdot \frac{n^2 \cdot 3^n}{5^{n-1}} \\
            && &\text{Remember:} \\
            && & 5^n = 5^{n-1} \cdot 5 \\
            &= \lim_{n \to \infty} \frac{5n^2}{3(n+1)^2} \\
            &= \lim_{n \to \infty} \frac{5}{3} \left(\frac{n}{n+1}\right)^2 \\
            &= \frac{5}{3}
        \end{align*}
        Since the limit of the ratio is greater than 1, by the ratio test, the series diverges.

\section{Root test}
    Use the root test when you have \(n\)th powers in your series. There are three outcomes (similar to the ratio test).
    First start off with taking the limit of the \(n\)th root of the absolute value of the series:
    \[\lim_{n \to \infty} \sqrt[n]{\left| a_n \right|} = L\] 
    \begin{itemize}
        \item If \(L < 1\) then the series absolutely converges.
        \item If \(L > 1\) then the series diverges.
        \item If \(L = 1\) then the test is inconclusive.
    \end{itemize}
    Note this is the same outcomes as the ratio test.
    
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} (-1)^{n-1} \cdot \frac{2^{n+3}}{(n+1)^n}\]
        This is alternating, but showing decreasing is going to be difficult. Its not all positive terms.
        Lets try the root test:
        \begin{align*}
            \lim_{n \to \infty} \sqrt[n]{|a_n|}
            &= \lim_{n \to \infty} \sqrt[n]{\left| (-1)^{n-1} \cdot \frac{2^{n+3}}{(n+1)^n} \right|} \\
            &= \lim_{n \to \infty} \sqrt[n]{\frac{2^3 \cdot 2^n}{(n+1)^n}} \\
            &= \lim_{n \to \infty} \sqrt[n]{2^3 \cdot \left(\frac{2}{n+1}\right)^n } \\
            &= \lim_{n \to \infty} \sqrt[n]{2^3} \cdot \left(\frac{2}{n+1}\right) \\
            &= \lim_{n \to \infty} 2^{3/n} \cdot \frac{2}{n+1} \\
            &= 0
        \end{align*}
        So by the root test, with the limit \(L < 1\) the series is absolutely convergent.

\newpage
\section{Review on series}
    \begin{enumerate}
        \item The first thing we look for in any series it the divergence test. If \(\lim a_n \neq 0\), then the series \(\sum a_n\) diverges.
        \item Look for known types of series that we can work with:
        \begin{enumerate}
            \item Geometric \[\sum ar^{n-1}\]
            converges if \(|r| < 1\) otherwise it diverges. Remember: the sum of this is \(\frac{a}{1-r}\).
            \item Telescoping series, first start by looking at partial sum \(S_n\), then take the limit
            \[\lim_{n \to \infty} S_n\]
            \item P-Series \[\sum \frac{1}{n^P}\]
            When \(P > 1\) the series converges, if \(P \leq 1\) it diverges.
        \end{enumerate}
        \item Try the integral test if the terms of \(a_n\)are positive, continuous and decreasing on the interval.
        Start by finding a function \(f(x)\) that models the series \(a_n\)
        \[\int_{1}^{\infty} f(x) \,\mathrm{d}x \]
        If the integral converges, then the series converges. If the integral diverges then the series diverges.
        \item If we have a series \(a_n\) where all the terms are positive and the series acts like a known series (Geometric, P-series, etc)
        we can try to use a comparison test (or limit comparison test).
        \begin{enumerate}
            \item If \(a_n < b_n\) and the series \(b_n\) converges, then the series \(a_n\) also converges.
            \item If \(a_n > b_n\) and the series \(b_n\) diverges, then the series \(a_n\) also diverges.
            \item For the limit comparison test:
            \[\lim_{n \to \infty} \frac{a_n}{b_n}\]
            If this exists, then both \(a_n\) and \(b_n\) have the same convergence/divergence.
        \end{enumerate}
        \item For an alternating series \(\sum (-1)^n a_n\) or \(\sum (-1)^{n-1} a_n\).
        You can show convergence by meeting these criteria:
        \begin{enumerate}
            \item Show limit of the series is 0. \[\lim_{n \to \infty} a_n = 0\]
            \item Show decreasing terms \[a_{n+1} \leq a_n \] or \[f'(x) < 0\]
        \end{enumerate}
        \item Try the ratio test for series with factorials and \(n\)th powers
        \[\lim_{n \to \infty} \frac{a_{n+1}}{a_n} = L \]
        \begin{enumerate}
            \item If \(L < 1\) then the series is absolutely convergent.
            \item If \(L > 1\) then the series is divergent.
            \item If \(L = 1\) then the test is inconclusive.
        \end{enumerate}
        \item Try the root test for series with \(n\)th powers. 
        \[\lim_{n \to \infty} \sqrt[n]{\left| a_n \right|} = L\] 
        \begin{enumerate}
            \item If \(L < 1\) then the series absolutely converges.
            \item If \(L > 1\) then the series diverges.
            \item If \(L = 1\) then the test is inconclusive.
        \end{enumerate}
    \end{enumerate}
    
    \subsection{Examples}
        \begin{enumerate}
            \item \[\sum_{n = 1}^{\infty} \frac{2n-1}{3n-1} \]
            This fails the divergence test!
            \item \[\sum_{n = 1}^{\infty} \left[ \frac{2}{3^n} - \frac{1}{n \cdot (n+1)} \right]\]
            This is a geometric and a telescoping series. Both would have to converge for it to converge.
            \item \[\sum_{n = 1}^{\infty} \left(\frac{1}{n}\right)^e \]
            This can be evaluated as a P-series. \(P = e > 1\)
            \item \[\sum_{n = 4}^{\infty} \frac{1}{n \sqrt{\ln n}} \]
            This one works well with the integral test.
            \item \[\sum_{n = 1}^{\infty} \frac{\ln n}{n^2} \]
            This one has single terms, so a comparison test should work well.
            Consider the comparison \(< \frac{\sqrt{n}}{n^2}\)
            \item \[\sum_{n = 1}^{\infty} \frac{\sqrt{n^3 - 2}}{n^4+3n^2-1} \]
            This has multiple terms, so look at how it behaves (the leading terms).
            Then take the limit comparison test where \[\lim_{n \to \infty} \frac{a_n}{b_n}\]
            \item \[\sum_{n = 1}^{\infty} (-1)^n \cdot \frac{\sqrt{n}}{n^2 + 1} \]
            This is an alternating series, so do the alternating series test.
            \item \[\sum_{n = 1}^{\infty} \frac{n}{2^n} \]
            You can do either the root test or the ratio test on this.
            Remeber: \[n^1 = n^{n/n} = \left(n^{1/n}\right)^n\]
            \item \[\sum_{n = 1}^{\infty} \frac{\sin n}{\sqrt{n^3 + 1}} \]
            Use the absolute value on this remembering: \[|\sin n| \leq 1\] then try other techniques.
        \end{enumerate}

\section{Power series}
    A series that contains some kind of variable \(x\) that is being rasied to some power \(n\).
    There are two different types of power series:
    \begin{enumerate}
        \item \[\sum_{n=0}^{\infty} a_n \cdot x^n\]
        Lets look at the first couple of terms of this series:
        \[= a_0 + a_1 x + a_2 x^2 + a_3 x^3 + \cdots\]
        This is a power series of the variable \(x\) that is centered at the origin (or 0).
        (Nothing is being added or subtracted from \(x\))
        \item \[\sum_{n = 0}^{\infty} a_n \cdot (x-c)^n \]
        Lets look at the first couple terms of this series:
        \[= a_0 + a_1 (x-c)^1 + a_2(x-c)^2 + a_3(x-c)^3 + \cdots\]
        This is a power series of the variable \(x\) with a center \(c\). 
        (\(c\) is a constant).
    \end{enumerate}
    Consider:
    \[\sum_{n = 0}^{\infty} (-1)^n \cdot \frac{x^n}{n!} \]
    You can tell this a power series because it has \(x^n\) in it.
    It looks like this is going to be centered at the origin.
    We can also see our \(a_n\) by plugging in the first \(n=0\) which makes the \(x\) evaluate to \(1\).
    You can also tell its an alternating power series because of the \((-1)^n\).
    Lets look at the pattern of the first couple of terms:
    \[= 1 - \frac{x}{1!} + \frac{x^2}{2!} - \frac{x^3}{3!} + \cdots\]\\
    \\
    Consider:
    \[\sum_{n=0}^{\infty} (-1)^n \cdot \frac{(x - \frac{\pi}{4})^{2n+1}}{(2n+1)!}\]
    Looks like a power series because it has the variable \(x\).
    It is centered at \(\frac{\pi}{4}\).
    Lets look at the first couple of terms:
    \[= \frac{(x - \frac{\pi}{4})}{1!} - \frac{(x - \frac{\pi}{4})^3}{3!} + \frac{(x - \frac{\pi}{4})^5}{5!} - \cdots\]
    This can be shown as a function of \(x\).
    \[f(x) = \sum_{n = 0}^{\infty} a_n (x - c)^n\]
    When the series is actually evaluated there isn't any more \(n\) and whats left is just a bunch of terms with \(x\).
    Then, you can actually plug in a value for \(x\) and you can tell if the power series converges/diverges.
    The sum of the series after plugging in a value for \(x\) is the output of the function.
    So, the function \(f(x)\) is defined to have the domain of all \(x\) such that \(f(x)\) converges.
    It is also good to note that:
    \[f(c) = a_0\]
    which defines the center of the series as \((c, a_0)\).
    The domain of \(f(x)\) will be an interval centered around \(c\).\\
    \\
    Convergence of a power series can be one of three things:
    \begin{enumerate}
        \item You can have a power series where the function is only defined at \(x = c\).
        This means that the radius of convergence \(r = 0\).
        This would define an interval of convergence at:
        \[0 \leq x \leq 0\]
        \item You can have a power series where it converges for all \(x\).
        This means that the radius of convergence \(r = \infty\).
        This would define an interval of convergence at:
        \[- \infty \leq x \leq \infty\]
        \item You can have a power series where values within a certain radius converge on
        \(|x-c| < R\).
        If \(|x-c| > R\) then it diverges.
        This would define an interval of convergence at:
        \[|x-c| < R\]
        \[-R < x - c < R\]
        \[c - R < x < c + R\]
    \end{enumerate}
    After you check the interval of convergence, you need to check each end point.
    Each of these end points need to be checked if included in interval you must use a convergence test.
    
    \subsection{Example}
        \[\sum_{n=0}^{\infty} x^n \]
        This is a power series with \(a_n = 1\).
        Check out the first couple of terms:
        \[= 1 + x + x^2 + x^3 + \cdots\]
        This might look weird at first but its actually a geometric series.
        So you can think of the function as:
        \[\sum_{n=0}^{\infty} 1 \cdot x^n\]
        This shows a geometric series with the values \(a = 1\) and \(r = x\).
        Geometric series when \(|r| < 1\).
        So this series converges when \(|x| < 1\).
        So the domain of our function \(f(x)\) is \(-1 < x < 1\).
        The sum of this series is:
        \[= \frac{1}{1-x}\]
        So this series actually represents \(f(x)\) on the interval \((-1, 1)\).
        \[f(x) = \sum_{n=0}^{\infty} x^n = \frac{1}{1-x}\] 
        
    \subsection{Example}
        \[\sum_{n=0}^{\infty} n! \cdot x^n \]
        We need to find the interval of convergence.
        Since we see the factorial, lets try the ratio test:
        \[\lim_{n \to \infty} \left| \frac{(n+1)!\cdot x^{n-1}}{n! \cdot x^n}\right|\]
        Since \(x\) is varying, you can't just drop the absolute value instantly.
        Lets simplify:
        \[\lim_{n \to \infty} \left| (n+1) \cdot x\right|\]
        We can strip the absolute value off of \(n\).
        \[\lim_{n \to \infty} (n+1) \cdot |x| \]
        Lets consider \(x\) not equaling 0. 
        Every value of \(x\) makes the limit evaulate to \(\infty\).
        But when \(x = 0\) it is 0.
        Which means by the ratio test when \(x \neq 0\) the series diverges.
        When \(x = 0\) it means that the series converges.
        Side note: The radius of convergence \(R = 0\) 
    
    \subsection{Example}
        \[\sum_{n=0}^{\infty}  (-1)^n \cdot \frac{x^{2n}}{(2n)!}\]
        Remember, this power series is a function in terms of \(x\).
        Lets find out where it converges with the ratio test:
        \begin{align*}
            &\lim_{n \to \infty} \left| \frac{(-1)^{n+1} \cdot \frac{x^{2(n+1)}}{(2(n+1))!}}{(-1)^n \cdot \frac{x^{2n}}{(2n)!}}\right| \\
            &= \lim_{n \to \infty}  \left| \frac{x^{2n+2}}{(2n+2)!} \cdot \frac{(2n)!}{x^{2n}}\right| \\
            && & \text{Note:} \\
            && & \frac{x^{2n+2}}{x^{2n}} = \frac{x^{2n} \cdot x^2}{x^{2n}} \\
            && &= x^2 \\
            && & \text{And:} \\
            && & \frac{(2n)!}{(2n + 2)!} \\
            && &= \frac{(2n)!}{(2n+2)(2n+1)(2n)!} \\
            && &= \frac{1}{(2n+2)(2n+1)} \\
            &= \lim_{n \to \infty} \frac{x^2}{(2n+2)(2n+1)} \\
            &= 0
        \end{align*}
        Note: the absolute value can be dropped at the second to last step because \(x\) is being squared.
        This shows that the series evaluates to 0 for any value of \(x\).
        So any values plugged in to \(x\) means that by the ratio test, the series converges.
        Therefore the radius of convergence \(R = \infty\).
        The domain of this function is \((-\infty, \infty)\).
        
    \subsection{Example}
        \[\sum_{n=1}^{\infty}  \frac{x^n}{n}\]
        We need to find the domain of the function in terms of \(x\).
        That means finding where it converges.
        Lets setup the ratio test:
        \begin{align*}
            \lim_{n \to \infty} \left| \frac{\frac{x^{n+1}}{n+1}}{\frac{x^n}{n}}\right|
            &= \lim_{n \to \infty} \left| \frac{x^{n+1}}{n+1} \cdot \frac{n!}{x^n}\right| \\
            &= \lim_{n \to \infty} \left| \frac{n}{n+1} \cdot x\right| \\
            &= \lim_{n \to \infty} \frac{n}{n+1} \cdot |x| \\
            && &\text{Note:} \\
            && &\lim_{n \to \infty} \frac{n}{n+1} = 1 \\
            &= |x|
        \end{align*}
        So by the ratio test if \(|x| < 1\) you'll have a convergent series.
        \[|x| < 1\]
        \[-1 < x < 1\]
        So the radius of convergence \(R = 1\).
        The center of the series is \(0\).
        Lets determine the endpoints to see if they are included in the interval.
        First plug in \(x = -1\):
        \begin{align*}
            \sum_{n=1}^{\infty}  \frac{x^n}{n} 
            &= \sum_{n=1}^{\infty}  \frac{(-1)^n}{n} \\
        \end{align*}
        This is an alternating harmonic series, which converges.
        This means that we include the endpoint \(x = -1\).
        Lets check the endpoint \(x = 1\):
        \begin{align*}
            \sum_{n=1}^{\infty}  \frac{x^n}{n} 
            &= \sum_{n=1}^{\infty}  \frac{(1)^n}{n} \\
        \end{align*} 
        This is a harmonic series which diverges.
        This means that we don't include the endpoint \(x = 1\).
        Therefore the interval of the series is:
        \[-1 \leq x < 1\]
    
    \subsection{Example}
        \[\sum_{n = 1}^{\infty} \frac{(x-2)^n}{n^2 \cdot 3^n} \]
        This is a power series with a center at \(2\).
        Lets start off by doing a ratio test:
        \begin{align*}
            \lim_{n \to \infty} \left| \frac{\frac{(x-2)^{n+1}}{(n+1)^2 \cdot 3^{n+1}}}{\frac{(x-2)^n}{n^2 \cdot 3^n}} \right|
            &= \lim_{n \to \infty} \left| \frac{(x-2)^{n+1}}{(n+1)^2 \cdot 3^{n+1}} \cdot \frac{n^2 \cdot 3^n}{(x-2)^n} \right| \\
            &= \lim_{n \to \infty} \left| \frac{(x-2) \cdot n^2}{3(n+1)^2} \right| \\
            &= \lim_{n \to \infty} \left( \frac{n}{n+1}\right)^2 \cdot \left| \frac{x-2}{3} \right| \\
            && &\text{Note:} \\
            && & \lim_{n \to \infty} \left( \frac{n}{n+1} \right)^2 \\
            && &=1 \\
            &= \left| \frac{x-2}{3}\right| \\
            &= \frac{|x-2|}{3}
        \end{align*}
        Remember if the result is less than 1 the series will converge.
        So:
        \[\frac{|x-2|}{3} < 1\]
        \[|x-2| < 3\]
        \[-3 < x-2 < 3\]
        \[-1 < x < 5\]
        The radius of convergence is \(R = 3\).
        Finally, you must check the endpoints to see if they are included in the interval.
        First lets try \(x = -1\)
        \begin{align*}
            \lim_{n \to \infty} \frac{(x-2)^n}{n^2 \cdot 3^n}
            &= \lim_{n \to \infty}  \frac{(-3)^n}{n^2 \cdot 3^n} \\
            &= \lim_{n \to \infty} \left(\frac{-3}{3}\right)^n \cdot \frac{1}{n^2} \\
            &=\lim_{n \to \infty} (-1)^n \cdot \frac{1}{n^2}
        \end{align*}
        This is an alternating series.
        By alternating series test, since the limit is 0 and the terms are decreasing, the series converges.
        Lets test \(x = 5\):
        \begin{align*}
            \lim_{n \to \infty} \frac{(x-2)^n}{n^2 \cdot 3^n}
            &= \lim_{n \to \infty}  \frac{(3)^n}{n^2 \cdot 3^n} \\
            &= \lim_{n \to \infty} \frac{1}{n^2}
        \end{align*}
        This is a p-series where \(P = 2\), so since \(P\) is greater than 1, the series converges.
        Therefore you can include both endpoints on the interval.
        \[-1 \leq x \leq 5\]
    
    \subsection{Example}
        \[\sum_{n=0}^{\infty} (-1)^n \cdot \frac{2^n \cdot x^n}{\sqrt{n+1}}\]
        This is a power series with the center at \(0\).
        Lets try the ratio test:
        \begin{align*}
            \lim_{n \to \infty} \left| \frac{(-1)^{n+1} \cdot \frac{2^{n+1} \cdot x^{n+1}}{\sqrt{(n+1)+1}}}{(-1)^n \cdot \frac{2^n \cdot x^n}{\sqrt{n+1}}} \right|
            &= \lim_{n \to \infty} \left| \frac{2^{n+1} \cdot x^{n+1}}{\sqrt{n+2}} \cdot \frac{\sqrt{n+1}}{2^n \cdot x^n} \right| \\
            &= \lim_{n \to \infty} \left| \sqrt{\frac{n+1}{n+2}} \cdot 2x \right| \\
            &= \lim_{n \to \infty}  \sqrt{\frac{n+1}{n+2}} \cdot 2 |x| \\
            && &\text{Note:} \\
            && &\lim_{n \to \infty}  \sqrt{\frac{n+1}{n+2}} = 1 \\
            &=2|x|
        \end{align*}
        So the serieses converges when:
        \[2|x| < 1\]
        \[|x| < \frac{1}{2}\]
        \[- \frac{1}{2} < x < \frac{1}{2}\]
        The radius of convergence is \(R = \frac{1}{2}\).
        The last thing to do is check the endpoints to see if they are to be included in the interval.
        Lets check \(x = - \frac{1}{2}\)
        \begin{align*}
            \sum_{n=0}^{\infty} (-1)^n \cdot \frac{2^n(- \frac{1}{2})^n}{\sqrt{n+1}}
            &= \sum_{n=0}^{\infty} \frac{1^n}{\sqrt{n+1}}
        \end{align*}
        We can use a limit comparison test to evalulate this series, lets compare it to \(\sum \frac{1}{\sqrt{n}}\):
        \begin{align*}
            \lim_{n \to \infty} \frac{\frac{1}{\sqrt{n+1}}}{\frac{1}{\sqrt{n}}}
            &= 1
        \end{align*}
        Since the limit exists, then by the limit comparison test, both of the series have the same result.
        We know that \(\sum \frac{1}{\sqrt{n}}\) diverges (P-series with \(P = \frac{1}{2}\)).
        Therefore by the limit comparison test we can say that the series compared to also diverges.
        So, we won't include this endpoint in the interval.
        It is also good to note that:
        \[\sum_{n=0}^{\infty} \frac{1}{\sqrt{n+1}} = \sum_{n = 1}^{\infty} \frac{1}{\sqrt{n}}\]
        So the limit comparison test isn't entirely needed. 
        Lets try the endpoint \(x = \frac{1}{2}\).
        \begin{align*}
            \sum_{n=0}^{\infty} (-1)^n \cdot \frac{2^n(\frac{1}{2})^n}{\sqrt{n+1}}
            &= \sum_{n=0}^{\infty} \frac{(-1)^n}{\sqrt{n+1}}
        \end{align*}
        This is an alternating series, so lets check the limit:
        \[\lim_{n \to \infty} \frac{1}{\sqrt{n+1}} = 0\]
        Check to see if it is decreasing:
        \[a_{n+1} < a_n\]
        \[\frac{1}{\sqrt{n+2}} < \frac{1}{\sqrt{n+1}}\]
        So the series is decreasing. 
        Therefore by the alternate series test we have convergence.
        So this point will be included on the interval of convergence.
        Overall our series of convergence is:
        \[- \frac{1}{2} < x \leq \frac{1}{2}\]

\section{Calculus with Power series}
    Lets assume we have a power series \(f(x)\):
    \[f(x) = \sum_{n=0}^{\infty} a_n (x-c)^n\]
    We'll talk about derivatives with power series first.
    Take a look at the first couple of terms:
    \[f(x) = a_0 + a_1(x-c) + a_2(x-c)^2 + a_3(x-3)^3 + \cdots\]
    Remember that all of the \(a\) terms are constants.
    Also note that when you take derivatives you can split the derivatives on sums and differences.
    Look at the first few terms derivatives:
    \[f'(x) = 0 + a_1 + 2a_2(x-c)^1 + 3a_3(x-c)^2 + \cdots\]
    So \(f'(x)\) really starts at \(a_1\) now.
    \[f'(x) = \sum_{n = 1}^{\infty} na_n(x-c)^{n-1}\]
    So comparing the two, you can tell that its just the chain rule!
    Now lets talk about integrating power series.
    Lets look at the first couple of terms of the integral:
    \[\int f(x) \,\mathrm{d}x = a_0(x-c) + \frac{1}{2}a_2(x-c)^2 + \frac{1}{3}a_2(x-c)^3 + \cdots\]
    So we can see the pattern thats happening:
    \[\int f(x) \,\mathrm{d}x = \sum_{n=0}^{\infty} \frac{a_n(x-c)^{n+1}}{n+1} + C\]
    You can tell this is just the basic rule integrating, power rule in reverse!
    So to summarize:
    \begin{enumerate}
        \item Derivatives of power series:
        \[f(x) = \sum_{n=0}^{\infty} a_n (x-c)^n\]
        \[f'(x) = \sum_{n = 1}^{\infty} na_n(x-c)^{n-1}\]
        \item Integrals of power series:
        \[f(x) = \sum_{n=0}^{\infty} a_n (x-c)^n\]
        \[\int f(x) \,\mathrm{d}x = \sum_{n=0}^{\infty} \frac{a_n(x-c)^{n+1}}{n+1} + C\]
    \end{enumerate}
    Remember, since these series have intervals of convergence.
    Its good to note that there is a potential to lose endpoints on derivatives, and gain endpoints on integrals.
    The rest of the interval of convergence will remain the same however.
    
    \subsection{Example}
        Find a power series representation for:
        \[\ln (1-x)\]
        on the interval \((-1, 1)\).
        We're looking for a function that when you either derive or integrate it gives that series.
        We can start with thinking about the integral of:
        \[\frac{1}{1-x}\]
        This is pretty close to what we want, but the negative sign is different.
        You can also think of the fraction \(\frac{1}{1-x}\) as the sum of a geometric series where \(a = 1\) and \(r = x\).
        \[\sum_{n = 1}^{\infty} 1 \cdot x^{n-1} \]
        Its good to note that this is the same series as:
        \[\sum_{n=0}^{\infty} x^n\]
        Since this is a geometric series, \(|r| < 1\) which is why the interval is \((-1, 1)\).
        So for this geometric power series to converge:
        \[|x| < 1\]
        So you can think of it like this
        \[\frac{1}{1-x} = 1 + x + x^2 + x^3 + x^4 + \cdots\]
        and integrate both sides:
        \begin{align*}
            \int \frac{1}{1-x} dx &= \int 1 + x + x^2 + x^3 + x^4 + \cdots dx \\
            - \ln (1-x) &= x + \frac{1}{2}x^2 + \frac{1}{3}x^3 + \cdots + C \\
            \ln (1-x) &= -x - \frac{1}{2}x^2 - \frac{1}{3}x^3 - \cdots - C 
        \end{align*}
        Let \(x = 0\):
        \[\ln 1 = -C\]
        \[C = 0\]
        So since we know \(C\) we just need to find a series that represents:
        \begin{align*}
            \ln (1-x) &= -x - \frac{1}{2}x^2 - \frac{1}{3}x^3 - \cdots \\
            \ln (1-x) &= -(x + \frac{1}{2}x^2 + \frac{1}{3}x^3 + \cdots) \\
            \ln (1-x) &= - \sum_{n = 1}^{\infty} \frac{x^n}{n}
        \end{align*}
        Remember that the series converges on the interval \((-1, 1)\).

\newpage
\section{Taylor and MacLaurin series}
    Suppose a function \(f\) has a power series representation at a point \(C\).
    \[f(x) = \sum_{n=0}^{\infty} a_n(x-c)^n\]
    If this is true, all of terms that include \(a\) will be constants. 
    You can continue to take derivatives of the terms until the \(n\)th derivative.
    This means that the \(n\)th derivative of \(f\) exists at \(C\).
    \[f^n(c)\]
    To find out what \(a_n\) is in terms of the derivative lets look at the first couple of terms of \(f(x)\).
    \[f(x) = a_0 + a_1(x-c) + a_2(x-c)^2 + a_3(x-c)^3 + \cdots + a_n(x-c)^n\]
    Lets look some derivatives:
    \begin{align*}
        f'(x) &= 0 + a_1 + 2a_2(x-c)^1 + 3a_3(x-c)^2 + \cdots + na_n(x-c)^{n-1} + \cdots \\
        f''(x) &= 0 + 0 + 2 \cdot 1 \cdot a_2 + 3 \cdot 2 \cdot a_3(x-c)^1 + \cdots + n(n-1) \cdots a_n (x-c)^{n-2} + \cdots \\
        f'''(x) &= 0 + 0 + 0 + 3 \cdot 2 \cdot 1 \cdot a_3 + \cdots + n(n-1)(n-2)a_n(x-c)^{n-3} + \cdots
    \end{align*}
    You can see eventually you get a constant for every term on each continued derivative.
    You can also see a pattern emerging with factorials.
    Lets look at the \(n\)th derivative:
    \[f^n(x) = n(n-1)(n-2) \cdots 3 \cdot 2 \cdot 1 \cdot a_n (x-c)^{n-n} + \cdots\]
    Look at what happens when you plug in \(c\).
    \[f^n(c) = n! \cdot a_n  \]
    We can then solve for \(a_n\):
    \[a_n = \frac{f^n(c)}{n!}\]
    So lets plug \(a_n\) into the original power series representation:
    \[f(x) = \sum_{n=0}^{\infty} a_n(x-c)^n\]
    becomes:
    \[f(x) = \sum_{n=0}^{\infty} \frac{f^n(c)}{n!} \cdot (x-c)^n\]
    This is whats called a Taylor series.
    Lets check out the first couple of terms of this Taylor series:
    \[f(x) = \sum_{n=0}^{\infty} \frac{f^n(c)}{n!} \cdot (x-c)^n = f(c) + f'(c)(x-c) + \frac{f''(c)(x-c)^2}{2!} + \cdots\]
    There is a special Taylor series where \(c = 0\) called the MacLaurin series:
    \[f(x) = \sum_{n=0}^{\infty} \frac{f^n(0)}{n!} \cdot x^n = f(0) + f'(0) \cdot x + \frac{f''(0)}{2!}\cdot x^2 + \cdots\]
    Remember, a function that has a power series representation will be have a Taylor series.
    If we find a Taylor series based on the derivatives of some function, that function usually represents the function.
    
    \subsection{Example}
        Find the Taylor series that represents this function at a certain point \(C = 0\):
        \[f(x) = e^x\]
        Lets tackle this in steps:
        \begin{enumerate}
            \item Find several derivatives of your function \(f\) and look for a pattern
            \[f(x) = e^x\]
            \[f'(x) = e^x\]
            \[f''(x) = e^x\]
            \[\cdots\]
            \[f^n(x) = e^x\]
            This one is a weird example because of the nature of derivatives but this definitely helps with other functions where you need to find the pattern.
            \item Plug in \(C\) and look for the pattern:
            \[f(0) = 1\]
            \[f'(0) = 1\]
            \[\cdots\]
            \[f^n(0) = 1\]
            \item Once you have those two parts, you can setup the series.
            So our function will look like this:
            \[f(x) = \sum_{n=0}^{\infty} \frac{f^n(0)}{n!}x^n\]
            Plug in our \(f(0) = 1\):
            \[f(x) = \sum_{n=0}^{\infty} \frac{1}{n!}x^n\]
            \item Now check out that series for convergence/divergence and find the interval.
            Lets try the ratio test:
            \begin{align*}
                \lim_{n \to \infty} \left| \frac{\frac{x^{n+1}}{(n+1)!}}{\frac{x^n}{n!}} \right|
                &= \lim_{n \to \infty} \left| \frac{x^{n+1}}{n+1} \cdot \frac{n!}{^n} \right| \\
                &= \frac{1}{n+1} \cdot |x| \\
                &= 0
            \end{align*}
            Since the limit is less than 1, by the ratio test, the series converges on:
            \[- \infty < x < \infty\]
        \end{enumerate}
        So \(f(x) = e^x \) can be represented by:
        \[\sum_{n = 0}^{\infty} \frac{x^n}{n!}\]
        on the interval \((- \infty, \infty)\).
        So lets look at the series when its being evaluated at a certain value, say \(2\):
        \[(f(2) = e^2 = 1 + 2 + \frac{2^2}{2} + \frac{2^3}{3!} + \cdots\]      
        This is weird because the series actually doesn't have an \(e\) in it, however it eventually ends up being \(e^2\).
        The more terms you add in the series the more accurate the value for \(e^2\) becomes.
    
    \subsection{Example}
        Find the Taylor series for:
        \[f(x) = \ln x\]
        at the value \(c = 1\).
        \begin{enumerate}
            \item Take some derivatives to look for a pattern:
            \begin{align*}
                f'(x) &= x^{-1} \\
                f''(x) &= -1 \cdot x^{-2} \\
                f'''(x) &= 2 \cdot 1 \cdot x^{-3} \\
                f^4(x) &= -3 \cdot 2 \cdot 1 \cdot x^{-4} \\
                f^5(x) &= 4 \cdot 3 \cdot 2 \cdot 1 \cdot x^{-5}
            \end{align*}
            It looks like the pattern of the \(n\)th derivative is:
            \[f^n(x) = \sum_{n=0}^{\infty} (-1)^{n-1}(n-1)! \cdot x^{-n}\]
            \item Plug in \(C = 1\)
            \begin{align*}
                f(1) &= 0 \\
                f'(1) &= 1 \\
                f''(1) &= -1 \\
                f'''(1) &= 2 \cdot 1 \\
                f^4(1) &= - 3 \cdot 2 \cdot 1 \cdot \\
                f^5(1) &= 4 \cdot 3 \cdot 2 \cdot 1 \\
            \end{align*}
            Note that the pattern starts at the first derivative.
            So the \(n\)th derivative of \(f\) at \(C = 1\) is:
            \[f^n(1) = (-1)^{n-1}(n-1)!\]
        \end{enumerate}
        So our Taylor series looks like this (we're not going to start at \(n = 0\) because the pattern starts at \(n = 1\)):
        \[\sum_{n=1}^{\infty} \frac{f^n(1) (x-c)^n}{n!}\]
        So now lets plug in \(f^n(1)\):
        \begin{align*}
            \sum_{n = 1}^{\infty} \frac{(-1)^{n-1}(n-1)!(x-1)^n}{n!}
            &= \sum_{n = 1}^{\infty} \frac{(-1)^{n-1}(x-1)^n}{n}
        \end{align*}
        Now lets check out the interval of convergence of this with the ratio test:
        \begin{align*}
            \lim_{n \to \infty} \left| \frac{\frac{(-1)^n(x-1)^{n+1}}{n+1}}{\frac{(-1)^{n-1}(x-1)^n}{n}} \right|
            &= \lim_{n \to \infty} \left| \frac{(x-1)^{n+1}}{n+1} \cdot \frac{n}{x-1)^n} \right| \\
            &= \lim_{n \to \infty} \left( \frac{n}{n+1} \right) \cdot \left| x-1 \right| \\
            && &\text{Note:} \\
            && &\lim_{n \to \infty} \left( \frac{n}{n+1} \right) = 1 \\
            &= |x-1|
        \end{align*}
        So our interval of convergence is:
        \[|x-1| < 1\]
        \[-1 < x - 1 < 1\]
        \[0 < x < 2\]
        We have a radius of convergence of \(R = 1\).
        Last thing we need to do is check the endpoints to see if they are to be included in the interval of convergence:
        Lets check \(x = 0\) first:
        \begin{align*}
            \sum_{n = 1}^{\infty} \frac{(-1)^{n-1}(x-1)^n}{n}
            &= \sum_{n = 1}^{\infty} \frac{(-1)^{n-1}(-1)^n}{n} \\
            &= \sum_{n = 1}^{\infty} \frac{(-1)^{2n-1}}{n} \\
            &= \sum_{n = 1}^{\infty} \frac{-1}{n} \\
            &= - \sum_{n = 1}^{\infty} \frac{1}{n} 
        \end{align*}
        Remember that the expression \(2n-1\) always gives odd numbers.
        This is harmonic series which diverges.
        So we won't include this in the interval of convegence.
        Lets check \(x = 2\):
        \begin{align*}
            \sum_{n = 1}^{\infty} \frac{(-1)^{n-1}(x-1)^n}{n}
            &= \sum_{n = 1}^{\infty} \frac{(-1)^{n-1} (1)^n}{n} \\
            &= \sum_{n = 1}^{\infty} \frac{(-1)^{n-1}}{n}
        \end{align*} 
        This is an alternating harmonic series, which converges by the alternating series test.
        So we'll include this value of \(x = 2\) in the interval.
        So the overall interval of convergence for the series is:
        \[0 < x \leq 2\]
        The function \(f(x) = \ln x\) can be represented by the Taylor series:
        \[\sum_{n = 1}^{\infty} \frac{(-1)^{n-1}(x-c)^n}{n}\]
        on the interval \((0, 2]\). 

    \subsection{Example}
        Lets find the MacLaurin series of:
        \[f(x) = \sin x\]
        Remember that we're looking for the Taylor series where \(C = 0\).
        We're looking for something that satisfies:
        \[\sum_{n=0}^{\infty} \frac{f^n(0)x^n}{n!}\]
        The first thing we need to look for is the \(n\)th derivative of \(f\):
        \begin{align*}
            f(x) &= \sin x \\
            f'(x) &= \cos x \\
            f''(x) &= - \sin x \\
            f'''(x) &= - \cos x \\
            f^4(x) &= \sin x \\
            \cdots \\
            f^n(x) &= ?
        \end{align*}
        We can't always find the \(n\)th derivative of \(f\) by just looking for the pattern of derivatives.
        So lets plug in \(C = 0\) and see if there is a more distinct pattern:
        \begin{align*}
            f(0) &= 0 \\
            f'(0) &= 1 \\
            f''(0) &= -1 \\
            f'''(0) &= 0 \\
            \cdots \\
            f^n(0) &= ?
        \end{align*}
        Same thing where there isn't a distinct pattern.
        If we list out the first terms of a general MacLaurin series:
        \begin{align*}
            \sum_{n=0}^{\infty} \frac{f^n(0)x^n}{n!}
            &= f(0) + f'(0)x + f''(0) \frac{x^2}{2!} + f'''(0) \frac{x^3}{3!} + \cdots
        \end{align*}
        Lets try plugging in numbers from the terms we wrote out before:
        \[= 0 + x + 0 + \frac{(-1)x^3}{3!} + 0 + \frac{x^5}{5!} + \cdots \]
        We can redefine our series and omit the \(0\)s from the series:
        \[= x - \frac{x^3}{3!} + \frac{x^5}{5!} - \frac{x^7}{7!} + \cdots\]
        When we redefine the series, we'll be using a new variable \(k\).
        \[\sum_{k=0}^{\infty} \frac{(-1)^k \cdot x^{2k+1}}{(2k+1)!}\]
        Lets check out of this MacLaurin series converges with the ratio test:
        \begin{align*}
            \lim_{k \to \infty} \left| \frac{\frac{(-1)^{k+1} x^{2(k+1)+1}}{(2(k+1)+1)!}}{\frac{(-1)^k x^{2k+1}}{(2k+1)!}}\right|
            &= \lim_{k \to \infty} \left| \frac{x^{2k+3}}{(2k+3)!} \cdot \frac{(2k+1)!}{x^{2k+1}} \right| \\
            &= \lim_{k \to \infty} \frac{1}{(2k+3)(2k+2)} \cdot x^2 \\
            &= 0
        \end{align*}
        Since the limit of the ratio test is less than 1, and it doesn't matter what value \(x\) we plug in, that means we have convergence on the interval:
        \[- \infty < x < \infty\]
        The radius of convergence is \(R = \infty\).
        So, the function \(f(x) = \sin x\) can be represented by the series:
        \[\sum_{n=0}^{\infty}  \frac{(-1)^n x^{2n+1}}{(2n+1)!}\]
        on the interval \((- \infty, \infty)\).
    
    \subsection{Example}
        Lets find the MacLaurin series for:
        \[f(x) = (1 + x)^k\]
        where \(k\) is a real number.
        Lets look at the first couple of terms to see if there is a pattern:
        \begin{align*}
            f'(x) &= k(1 + x)^{k-1} \\
            f''(x) &= k(k-1)(1+x)^{k-2} \\
            f'''(x) &= k(k-1)(k-2)(1+x)^{k-3} \\
            f^4(x) &= k(k-1)(k-2)(k-3)(1+x)^{k-3} \\
            \cdots \\
            f^n(x) &= k(k-1)(k-2) \cdots (k-n+1) (1+x)^{k-n}
        \end{align*}
        Lets plug in \(x = 0\):
        \[f^n(0) = k(k-1)(k-2) \cdots (k-n+1)\]
        So our series is starting to look like:
        \[f(x) = (1 + x)^k = \sum_{n=0}^{\infty} \frac{f^n(0)}{x!} \cdot x^n\]
        Lets plug in our expression for the \(n\)th derivative of \(f\):
        \[\sum_{n=0}^{\infty} \frac{k(k-1)(k-2) \cdots (k-n+1)}{n!} \cdot x^n\]
        If we start to list out the terms of this series we can see how to represent \((1+x)^k\).
        So really we can represent the function like this:
        \[(1+x)^k = 1 + kx + \frac{k(k-1)x^2}{2!} + \frac{k(k-1)(k-2)x^3}{3!} + \cdots\]
        This is called a binomial series.
        So this series basically gives you back a line of Pascal's triangle.
        It can be shown like:
        \[(1+x)^k = \sum_{n=0}^{\infty} \binom{k}{n} x^n\]
        \begin{itemize}
            \item If \(k\) is a positive integer, then this series converges for all values of \(x\), with an interval of convergence of \(- \infty < x < \infty\).
            \item If \(k\) is not a positive integer, then the series will converge, but only if \(-1 < x < 1\).
            \begin{itemize}
                \item If \(0 < k < 1\) then the endpoint 1 is included in the interval: \(-1 < x \leq 1\).
                \item If \(k \geq 0\) then we can include both endpoints in the interval: \(-1 \leq x \leq 1\).
                \item Otherwise we don't include either endpoint.
            \end{itemize}
        \end{itemize}
    
    \subsection{Example}
        \[f(x) = \sqrt{1+x}\]
        This is a binomial series with \(k = \frac{1}{2}\).
        Since \(k\) is not a positive interger, but it is positive, it should converge on the interval \(-1 \leq x \leq 1\).
        Lets try to represent this with a Taylor/MacLaurin series. 
        \begin{align*}
            (1+x)^{1/2} &= 1 + \frac{1}{2}x + \frac{\frac{1}{2} \cdot (\frac{1}{2} - 1)x^2}{2!} + \cdots + \frac{\frac{1}{2}(\frac{1}{2}-1)(\frac{1}{2}-2) \cdots (\frac{1}{2} - n + 1)x^n}{n!} \\
            (1+x)^{1/2} &= 1 + \frac{1}{2}x - \frac{x^2}{2! \cdot 2^2} + \frac{3x^3}{3! \cdot 2^3} - \frac{3 \cdot 5 \cdot x^4}{4! \cdot 2^4} + \cdots + \frac{1 \cdot 3 \cdot 5 \cdots (2n-3)x^n}{n! \cdot 2^n} \\
            (1+x)^{1/2} &= 1 + \frac{1}{2}x + \sum_{n=2}^{\infty} \frac{(-1)^{n+1} \cdot 1 \cdot 3 \cdot 5 \cdots (2n-3)}{n! \cdot 2^n}
        \end{align*}
        So \(f(x)\) can be represented by this series on the interval \(-1 \leq x \leq 1\).
        Since \(k = \frac{1}{2}\), the endpoints of the interval are included.

    \subsection{Common MacLaurin series}
        \begin{enumerate}
            \item \[\frac{1}{1-x} = 1 + x + x^2 + x^3 + \cdots = \sum_{n=0}^{\infty} x^n\]
            This is a geometric series that converges on the inteval \(-1 < x < 1\).
            \item \[e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots = \sum_{n=0}^{\infty} \frac{x^n}{n!}\]
            This converges for all real numbers \(- \infty < x < \infty\).
            \item \[\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}\]
            This converges for all real numbers \(- \infty < x < \infty\).
            \item \[\cos x = 1 - \frac{x^2}{2!} + \frac{x^4}{4!} - \cdots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{(2n)!}\]
            This converges for all real numbers \(- \infty < x < \infty\).
            \item \[\ln (1+x) = x - \frac{x^2}{2} + \frac{x^3}{3} - \cdots = \sum_{n=0}^{\infty} \frac{(-1)^n x^n}{n}\]
            This converges on the interval \(-1 < x \leq 1\).
            \item \[\sin^{-1} x = x + \frac{x^3}{2 \cdot 3} + \frac{1 \cdot 3x^5}{2 \cdot 4 \cdot 5} + \cdots = \sum_{n=0}^{\infty} \frac{(2n)! \cdot x^{2n+1}}{(2^n n!) (2n+1)}\]
            This converges on \(-1 \leq x \leq 1\).
            \item \[\tan^{-1} x = x - \frac{x^3}{3} + \frac{x^5}{5} - \cdots = \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{2n+1}\]
            This converges on \(-1 \leq x \leq 1\).
            \item \[(1+x)^k = \sum_{n=0}^{\infty} \binom{k}{n} x^n\]
            The binomal series, it converges on \(-1 < x < 1\).
        \end{enumerate}

    \subsection{Example}
        Find the Taylor series at the point \(c = 2\) for:
        \[f(x) = \frac{1}{1+x}\]
        Manipulate the function until it fits the \((x - c)\) in a Taylor series:
        \[= \frac{1}{1+(x - 2) + 2}\]
        \[= \frac{1}{3 + (x - 2)}\]
        Lets make it so it fits the common Taylor series \(\frac{1}{1-x}\):
        \[= \frac{1}{3} \left[ \frac{1}{1 + \frac{(x-2)}{3}} \right]\]
        \[= \frac{1}{3} \left[ \frac{1}{1- (- \frac{x-2}{3})} \right]\]
        So lets see how this looks when plugging into the terms (look at previous section for terms):
        \[= \frac{1}{3} \left[ 1 + \left[ - \frac{(x-2)}{3}\right] + \left[ - \frac{(x-2)}{3} \right]^2 + \left[ - \frac{(x-2)}{3} \right]^3 + \cdots \right] \]
        Do some simplifying and look for patterns:
        \[= \frac{1}{3} \left[ 1 - \frac{(x-2)}{3} + \frac{(x-2)^2}{3^2} - \frac{(x-2)^3}{3^3} + \cdots \right]\]
        This looks like the series:
        \[= \frac{1}{3} \cdot \sum_{n=0}^{\infty}  \frac{(-1)^n(x-2)^n}{3^n}\]
        \[= \sum_{n=0}^{\infty}  \frac{(-1)^n(x-2)^n}{3^{n+1}}\]
        So \(f(x)\) can be represented by the series:
        \[\sum_{n=0}^{\infty}  \frac{(-1)^n(x-2)^n}{3^{n+1}}\]
        The last thing to do is make sure that your \(x\) values correctly correspond to the Taylor series interval.
        The convergence of this taylor series with just "\(x\)" is \(-1 < x < 1\), but we have a value of \(\frac{-(x-2)}{3}\).
        So set that in our interval:
        \[-1 < \frac{-(x-2)}{3} < 1\]
        \[-3 < -(x-2) < 3\]
        \[3 > x-2 > -3\]
        \[5 > x > -1\]
        So the interval of convergence is \(-1 < x < 5\).
    
    \subsection{Example}
        Find the MacLaurin series for:
        \[f(x) = x^2 \sin 2x\]
        Remember \(C = 0\) in MacLaurin series.
        Also note if:
        \[\sin x = x - \frac{x^3}{3!} + \frac{x^5}{5!} - \cdots\]
        then
        \[\sin 2x = 2x - \frac{(2x)^3}{3!} + \frac{(2x)^5}{5!} - \cdots\]
        Look for the pattern of the series:
        \[= 2x - \frac{2^3 x^3}{3!} + \frac{2^5 x^5}{5!} - \cdots\]
        So it looks like our series is alternating, and starts with a positive. It also has odd numbers.
        So our series is:
        \[\sum_{n=0}^{\infty} \frac{(-1)^n \cdot 2^{2n+1} \cdot x^{2n+1}}{(2n+1)!}\]
        Lets multiply the terms here by \(x^2\) so it looks like the original:
        \begin{align*}
            x^2 \sin 2x
            &= \sum_{n=0}^{\infty} \frac{(-1)^n \cdot 2^{2n+1} \cdot x^{2n+1}}{(2n+1)!} \cdot x^2 \\
            &= \sum_{n=0}^{\infty} \frac{(-1)^n \cdot 2^{2n+1} \cdot x^{2n+3}}{(2n+1)!}
        \end{align*}
        Since we know \(\sin x\) is convergence on \(- \infty < x < \infty\), \(\sin 2x\) is also convergent on that interval.
        \(f(x) = x^2 \sin 2x\) can be represented by the series:
        \[\sum_{n=0}^{\infty} \frac{(-1)^n \cdot 2^{2n+1} \cdot x^{2n+3}}{(2n+1)!}\]
        on the interval \(- \infty < x < \infty\).
    
    \subsection{Example}
        Find the MacLaurin series for:
        \[f(x) = \sinh x\]
        Remember:
        \begin{align*}
            \sinh x &= \frac{e^x - e^{-x}}{2} \\
            &= \frac{1}{2}e^x - \frac{1}{2}e^{-x}
        \end{align*}
        So lets use the common pattern from our known Taylor series:
        \[e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots \]
        Lets make this series behave more like our known:
        \[= \overbrace{\frac{1}{2} \left[ 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots \right]}^{\frac{1}{2}e^x} - \overbrace{\frac{1}{2} \left[ 1 - x + \frac{x^2}{2!} - \frac{x^3}{3!} + \cdots \right]}^{\frac{1}{2}e^{-x}}\]
        Look at what you can simplify:
        \[= \overbrace{\frac{1}{2} \left[ \cancel{1} + x + \cancel{\frac{x^2}{2!}} + \frac{x^3}{3!} + \cdots \right]}^{\frac{1}{2}e^x} - \overbrace{\frac{1}{2} \left[ \cancel{1} - x + \cancel{\frac{x^2}{2!}} - \frac{x^3}{3!} + \cdots \right]}^{\frac{1}{2}e^{-2}}\]
        All of the even powered terms cancel, and all of the odd powered terms get added together:
        \begin{align*}
            &= \frac{1}{2} \left[ 2x + \frac{2x^3}{3!} + \frac{2x^5}{5!} + \cdots \right] \\
            &= x + \frac{x^3}{3!} + \frac{x^5}{5!} + \cdots \\
            &= \sum_{n=0}^{\infty} \frac{x^{2n+1}}{(2n+1)!}
        \end{align*}
        So our \(f(x)\) can be represented by the series:
        \[\sum_{n=0}^{\infty} \frac{x^{2n+1}}{(2n+1)!}\]
        that converges on the interval \(- \infty < x < \infty\) (because the MacLaurin series we used to compare this to also converges on the same interval).
    
    \subsection{Example}
        Consider this:
        \[\int e^{-x^2} \,\mathrm{d}x \]
        Firstly, remember that:
        \[e^x = 1 + x + \frac{x^2}{2!} + \frac{x^3}{3!} + \cdots\]
        Try to make our example look like that:
        \begin{align*}
            e^{-x^2} &= 1 - x^2 + \frac{(-x^2)^2}{2!} + \frac{(-x^2)^3}{3!} + \cdots \\
            &= 1 - x^2 + \frac{x^4}{2!} - \frac{x^6}{3!} + \cdots
        \end{align*}
        This can be represented as a series:
        \[= \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{n!}\]
        This converges on \(- \infty < x < \infty\).
        We can actually integrate both sides of this equation:
        \begin{align*}
            \int e^{-x^2} \,\mathrm{d}x &= \int \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{n!} \mathrm{d}x \\
            &= \sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)n!} + C
        \end{align*}
        This idea allows you integrate functions that normally aren't able to be integrated by other methods.
        Remember, integrating series don't change their interval of convergence.

\newpage
\section[Taylor polynomials]{Approximating functions using Taylor polynomials}
    Based on Taylor series, we can use a Taylor polynomial to closely mimic a function around a certain point for a certain interval.
    Lets say we have a function:
    \[f(x) = f(c) + f'(c)(x-c) + \frac{f''(c)(x-c)^2}{2!} + \cdots + \frac{f^n(c)(x-c)^n}{n!} + \cdots\]
    Remember this series goes forever. So lets consider stopping it at the \(n\)th term.
    Now the series won't perfectly represent the function because it is stopping short of \(\infty\).
    If a Taylor series does represent the function and we have the the entire series, it can represent it.
    However, the series stopped short at \(n\) is considered a Taylor polynomial of the \(n\)th degree.
    \[f(x) = \overbrace{\underbrace{f(c) + f'(c)(x-c) + \frac{f''(c)(x-c)^2}{2!} + \cdots + \frac{f^n(c)(x-c)^n}{n!}}_{n \text{th degree Taylor polynomial}} \underbrace{+ \cdots}_{R_n(x)}}^{\text{Taylor series}}\]
    There is certainly a difference between a Taylor series and a Taylor polynomial.
    This little extra is called the remainder of the Taylor polynomial, we use \(R_n\) to show the remainder.
    So the Taylor polynomial plus \(R_n\) equals the Taylor series.
    \[R_n(x) = \frac{f^{n+1}(z)(x-c)^{n+1}}{(n+1)!} \]
    The \(z\) here is some number between \(c\) and \(x\).
    Pick \(z\) so you get the largest error you can.
    This can be used to approximate how close our Taylor polynomial is to the function.
    
    \subsection{Example}
        Approximate the value of \(\ln 1.1\) with a 4th degree Taylor polynomlial:
        \[f(x) = \ln x\]
        Find a Taylor polynomial at some point "close".
        Remember in our case \(x = 1.1\), and our \(C\) will equal 1.
        We want to choose a value of \(C\) that is close to our value of \(x\).
        Lets look at some derivatives:
        \begin{align*}
            f(x) &= \ln x 
            &f(1) &= 0 \\
            f'(x) &= \frac{1}{x}
            &f'(1) &= 1 \\
            f''(x) &= - \frac{1}{x^2}
            &f''(1) &= -1 \\
            f'''(x) &= \frac{2}{x^3}
            &f'''(1) &= 2 \\
            f^4(x) &= - \frac{6}{x^4}
            &f^4(1) &= -6 \\
        \end{align*}
        We also need to find our 5th derivative because that will be our error \(R_n\):
        \begin{align*}
            f^5(x) &= \frac{24}{x^5}
            &f^5(1) &= 24
        \end{align*}
        Remember, \(C = 1\).
        We're not really looking for a pattern here, we're trying to take part of a Taylor series to approximate the value.
        Lets try to build our Taylor polynomial from looking at these terms (\(P_4(x)\) represents our 4th degree Taylor polynomial):
        \begin{align*}
            P_4(x) = f(1) + f'(1)(x-1) + \frac{f''(1)(x-1)^2}{2!} + \frac{f'''(1)(x-1)^3}{3!} + \frac{f^4(1)(x-1)^4}{4!}
        \end{align*}
        Plug in the numbers that we know:
        \begin{align*}
            P_4(x) &= 0 + 1(x-1) - \frac{(x-1)^2}{2} + \frac{2(x-1)^3}{3!} - \frac{6(x-1)^4}{4!} \\
            &= (x-1) - \frac{(x-1)^2}{2} + \frac{(x-1)^3}{3} -\frac{(x-1)^4}{4}
        \end{align*}
        This polynomial approximates \(f(x) = \ln x\) around the number \(1\).
        So if we want to approximate the function evaluated at \(1.1\), then we can plug in \(1.1\) into our approximating polynomial that we have:
        \begin{align*}
            P_4(1.1) &= .1 - \frac{.1^2}{2} + \frac{.1^3}{3} - \frac{.1^4}{4} \\
            &\approx 0.0953083
        \end{align*}
        This is an approximation of \(\ln 1.1\).
        For our error \(R_n\):
        \begin{align*}
            R_4(x) &= \frac{f^{4+1}(z) (x-c)^{4+1}}{(4+1)!} \\
            &= \frac{f^5(z)(x-1)^5}{5!}
        \end{align*}
        Lets use the \(f^5(x) = \frac{24}{x^5}\) we found earlier, and lets pick a value for \(z\) to get the largest error we can.
        Since the fifth derivative is a fraction, the lower number for \(z\) will give a bigger error, so we'll choose \(1\) (\(f^5(z) = 24\)).
        Remember \(C \leq z \leq x\) or in our case \(1 \leq x \leq 1.1\):
        \begin{align*}
            R_4(x) &= \frac{24(1.1-1)^5}{5!} \\
            &= \frac{.1^5}{5} \\
            &= .000002
        \end{align*}
        That means our approximation of \(0.0953083\) is within \(.000002\) of the actual value.
    
    \subsection{Example}
        Find the second degree Taylor polynomial at \(C = 4\), with error \(R_n\) on the interval \([3, 5]\) of:
        \[f(x) = \sqrt{x}\]
        Lets list out some derivatives:
        \begin{align*}
            f(x) &= \sqrt{x}
            & f(4) &= 2\\
            f'(x) &= \frac{1}{2} x^{-1/2}
            &f'(4) &= \frac{1}{4}\\
            f''(x) &= - \frac{1}{4} x^{-3/2}
            &f''(4) &= - \frac{1}{32}\\
            f'''(x) &= \frac{3}{8} x^{-5/2}
            &f'''(4) &= \frac{3}{256}\\
        \end{align*}
        The problem is asking for the second degree polynomial, however we take it out to the third degree because that will become our error \(R_n\).
        Lets write out the terms of the polynomial:
        \begin{align*}
            P_2(x) &= f(4) + f'(4)(x-4) + \frac{f''(4)(x-4)^2}{2} \\
            &= 2 + \frac{1}{4}(x-4) - \frac{1}{64}(x-4)^2
        \end{align*}
        This is the Taylor polynomial to approximate the function \(f(x) = \sqrt{x}\) around the value \(4\).
        The next step is to find the error on the interval.
        \begin{align*}
            R_2(x) &= \frac{f'''(z) (x-4)^3}{3!} \\
            &= \frac{3}{8z^{5/2}} \cdot \frac{(x-4)^3}{3!}
        \end{align*}
        We pick \(x = 5\) and \(z = 3\) to maximize the error.
        Remember \(C \leq z \leq x\)
        \begin{align*}
            R_2(x) &= \frac{3}{8 \cdot 3^{5/2}} \cdot \frac{(5-4)^3}{3!} \\
            &= \frac{1}{16 \cdot 3^{5/2}} \\
            &\approx .004
        \end{align*}
        So we know our Taylor polynomial can approximate values around the value \(4\), but what this says it that on the interval
        \([3, 5]\) we can approximate the values to within \(.004\) of the value.

    \subsection{How to determine when a function can be represented by a Taylor series}
        When does a function have a Taylor series representation?
        If we can express a function as a Taylor polynomial \(P_n(x)\), then the rest of the Taylor series is in the remainder \(R_n(x)\):
        \[f(x) = P_n(x) + R_n(x)\]
        So if this is true, then:
        \[P_n(x) = f(x) - R_n(x)\]
        This is only true if the limit of \(R_n(x)\) at \(\infty\) goes to \(0\).
        So, if:
        \[\lim_{n \to \infty} R_n(x) = 0\]
        then the function \(f(x)\)can be repsented by a Taylor series at a point \(C\).
        So if \(n\) goes to \(\infty\), then the Taylor polynomial \(P_n(x)\) \textbf{is} the Taylor series.
        \textit{Note:} \[\lim_{n \to \infty} \frac{|x|^n}{n!} = 0\]

    \subsection{Example}
        Show that the Taylor series
        \[\sum_{n=0}^{\infty} \frac{x^n}{n!}\]
        actually represents the function \(f(x) = e^x\).
        We need to show that the limit of the error \(R_n\) goes to \(0\).
        To do that we need to find out what \(R_n\) is:
        \[R_n(x) = \frac{f^{n+1}(z)(x-c)^{n+1}}{(n+1)!}\]
        We can see from the original problem that \(C = 0\).
        Since each derivative of \(e^x\) is itself, the \((n+1)\)th derivative is \(e^x\) also.
        \[R_n(x) = \frac{e^z (x)^{n+1}}{(n+1)!}\]
        Now lets find the interval, remember \(C \leq z \leq x\), we have two cases:
        \begin{align*}
            0 < z < x && x < z < 0
        \end{align*}
        Lets show both of those cases:
        \begin{enumerate}
            \item \(x\) is positive:
            \[0 < z < x\]
            If thats true, then:
            \[z < x\]
            \[e^z < e^x\]
            So:
            \[0 \leq R_n(x) = \frac{e^z x^{n+1}}{(n+1)!} \leq \frac{e^x x^{n+1}}{(n+1)!}\]
            Now lets look at the limit:
            \[\lim_{n \to \infty} \frac{e^x x^{n+1}}{(n+1)}! = 0\]
            Therefore by the Squeeze theorem:
            \[0 \leq \lim_{n \to \infty} R_n(x) \leq 0\]
            \[\lim_{n \to \infty} R_n(x)\]
            \item \(x\) is negative:
            \[x < z < 0\]
            If thats true, then:
            \[z < 0\]
            \[e^z < e^0\]
            \[e^z < 1\]
            We can consider the absolute value of the remainder:
            \[0 < |R_n(x) = \left| \frac{e^z x^{n+1}}{(n+1)!} \right| < \frac{1 \cdot x^{n+1}}{(n+1)!}\]
            So lets use Squeeze theorem:
            \[\lim_{n \to \infty} 0 < \lim_{n \to \infty} R_n(x) < \lim_{n \to \infty} \frac{x^{n+1}}{(n+1)!}\]
            Therefore:
            \[\lim_{n \to \infty} R_n(x) = 0\]
        \end{enumerate}
        Since we have shown that the limit of \(R_n(x)\) goes to \(0\) when \(n \to \infty\) on both intervals, it proves that the Taylor series
        is a representation of the function \(f(x) = e^x\).
    
    \subsection{Example}
        Show that the Taylor series
        \[\sum_{n=0}^{\infty} \frac{(-1)^n \cdot x^{2n+1}}{(2n+1)!}\]
        is a representation of the function \(f(x) = \sin x\).
        Remember, ultimately we need to show that the remainder of the Taylor polynomial goes to zero when \(n \to \infty\).
        \[R_n(x) = \frac{f^{n+1} x^{n+1}}{(n+1)!}\]
        We need to find an expression for the \((n+1)\)th derivative of \(f\).
        Remember that continual derivatives of the function \(f(x) = \sin x\) is either going to \(\pm \sin x\) or \(\pm \cos x\).
        So any value of \(x\) is going to be between \(-1\) and \(1\).
        So:
        \[-1 \leq f^{n+1}(z) \leq 1\]
        \[\left| f^{n+1}(z) \right| \leq 1\]
        So we can then show:
        \[0 < \left| R_n(x) \right| = \frac{f^{n+1}(z) x^{n+1}}{(n+1)!} \leq \left| \frac{1 \cdot x^{n+1}}{(n+1)!} \right|\]
        So lets use the Squeeze theorem:
        \[\lim_{n \to \infty} 0 \leq \lim_{n \to \infty} \left| R_n(x) \right| \leq \lim_{n \to \infty} \left| \frac{1 \cdot x^{n+1}}{(n+1)!} \right|\]
        \[0 \leq \lim_{n \to \infty} \left| R_n(x) \right| \leq 0 \]
        So:
        \[\lim_{n \to \infty} \left| R_n(x) \right| = 0\]
        So, the Taylor series is a representation of the function!

\chapter{Parametric equations}

\section{Plane curves}
    A plane curve is defined as "the motion of an object in a plane".
    There are a few problems with defining a plane curve like a normal function, (like a function in terms of \(x\) and \(y\)):
    \begin{enumerate}
        \item Many times the plane curves are not functions.
        \item Even if the plane is a function, they can't always be explicitly defined in terms of a single variable,
        and they don't tell where the object is at a given time.
        \item No direction is given. We need to know start and stop points.
    \end{enumerate} 
    To deal with these problems we create what are called parametric equations.

\section{Intro to parametric equations}
    Instead of having \(x\) as a function of \(y\) (or vice versa), we're going to define \((x, y)\) as a function of an independent variable \(T\) for time:
    \begin{align*}
        x = f(T) &&
        y = g(T)
    \end{align*}
    Define motion in both the \(x\) and \(y\) directions as a function of a new independent variable \(T\) over a common domain \(I\).
    This is a better way to define a plane curve because each variable can now be described as functions on their own.
    The \(T\) is called the parameter, and \(I\) is the parameter's interval. 
    Note:
    \begin{itemize}
        \item \(T\) is typically thought of as time.
        So for some interval \[T = [a, b]\] \(T\) will start at an initial point \(a\) and end at a terminal point \(b\).
        \item The initial point will start at \(T = a\), this is where start our motion.
        This is the point \((f(a), g(a))\).
        \item The terminal point ends at \(T = b\), this is where the motion stops.
        This is the point \((f(b), g(b))\).
        \item This motion travels along a trajectory with a specific orientation.
    \end{itemize}

    \subsection{Example}
        Suppose we have:
        \begin{align*}
            x = T^2 - 4 &&
            y = 2T
        \end{align*}
        on the interval \(-1 \leq T \leq 2\).
        Lets start by plugging in some \(T\) values to see whats going on:
        \begin{align*}
            \begin{tabular}{l | r}
                \(T\) & \((x, y)\) \\
                \hline
                -1 & (-3,-2) \\
                -1/2 & (\(\frac{-15}{4}\), -1) \\
                0 & (-4, 0) \\
                1/2 & (\(\frac{-15}{4}\), 1)\\
                1 & (-3, 2) \\
                2 & (0, 4)
            \end{tabular}
        \end{align*}
        So we can see our motion starts at \((-3, -2)\) when \(T = -1\).
        Our motions ends when \(T = 2\) at the point \((0, 4)\).
        However, there is a better way to do this.
        Instead of plugging in a bunch of points, lets try to combine the two functions given to us:
        \begin{align*}
            x = T^2 - 4 &&
            y &= 2T \\
            && T &= \frac{y}{2} \\
            && \text{Plug into \(x\)} \\
            x = \left( \frac{y}{2} \right)^2 - 4
        \end{align*}
        A lot of times you can express the given functions as a single function in terms of \(x\) and \(y\), however
        you still need to find the initial and terminal points.
    
    \subsection{Example}
        \begin{align*}
            x = \sqrt{T} &&
            y = T
        \end{align*}
        This problem is given to us without an interval. 
        When this is the case you must use the natural domain, where the domain of each of these functions is going to determine what our overall domain is.
        The domain of \(y\) in this case is all real numbers, however the domain of \(x\) is:
        \[T \geq 0\]
        This problem can be rewritten as the simple function:
        \[x = \sqrt{y}\]
        \[y = x^2\]
        This is a parabola, however it doesn't represent the parametric equation given to us.
        Note when \(T\) equals 0, the the \((x, y)\) point is the origin, this is our intial point.
        Since \(T\) keeps going to \(\infty\) there isn't a terminal point.
        The curve travels in the direction from \(0 \to \infty\).
    
    \subsection{Example}
        \begin{align*}
            x = T &&
            y = T^2
        \end{align*}
        We can notice that \(y = x^2\), which is the same as the last example. 
        We can start with the simple graph of the parabola \(y = x^2\), but lets use our parameter to determine where it starts and stops.
        There aren't any restrictions for the parameter \(T\), so the interval for our motion is \((- \infty, \infty)\).
        You can tell if the interval is correct by "plugging in" these to see if it matches the behavior of the graph.
        \[\text{As } T \to - \infty: x \to - \infty, y \to \infty\]
        \[\text{As } T \to \infty: x \to \infty, y \to \infty\]
        The direction is from left to right.
        
    \subsection{Example}
        \begin{align*}
            x = a \cos \theta &&
            y = a \sin \theta &&
            a > 0
        \end{align*}
        \(\theta\) is the parameter.
        \(a\) is just a constant here.
        We can start to solve for the parameter using both equations, but not all the way down to the inverse functions.
        \begin{align*}
            \cos \theta = \frac{x}{a} &&
            \sin \theta = \frac{y}{a}
        \end{align*}
        Now we can use the Pythagorean identity:
        \[\cos^2 \theta + \sin^2 \theta = 1\]
        \[\left( \frac{x}{a} \right)^2 + \left(\frac{y}{a}\right)^2 = 1\]
        \[x^2 + y^2 = a^2\]
        This reveals that our variable \(a\) is the radius of a circle centered at the origin.
        Without an interval given to us we don't know where the initial and temrinal points are, and we don't know the direction of motion.
        For demonstration lets try the interval \(I = [0, \pi]\):
        \begin{align*}
            \theta = 0 : x = a, y = 0 \\
            \theta = \pi : x = -a, y = 0
        \end{align*}
        The direction is traveling counter-clockwise on the circle.
        
    \subsection{Example}
        \begin{align*}
            x = \sin T &&
            y = \sin 2T &&
            0 \leq T \leq 2 \pi
        \end{align*}
        The \(x\) variable is as isolated as we want it.
        But we can isolate the \(y\) to solve for a \(\cos T\):
        \begin{align*}
            y &= \sin 2T \\
            y &= 2 \sin T \cos T \\
            y &= 2 x \cos T \\
            \frac{y}{2x} &= \cos T
        \end{align*}
        Now lets use our Pythagorean identity:
        \begin{align*}
            \cos^2 T + \sin^2 T &= 1 \\
            \left(\frac{y}{2x}\right)^2 + x^2 &= 1 \\
            \frac{y^2}{4x^2} + x^2 &= 1 \\
            y^2 + 4x^4 &= 4x^2 \\
            4x^4 - 4x^2 + y^2 &= 0 \\
        \end{align*}
        In terms of \(x\) it is an even functions. So there will be some symmetry about the y-axis.
        Since \(y\) is also being squared, it is also even, so it is symmetrical about the x-axis also.
        We can plug in some values in the first quadrant and get all of the other quadrant's points.
        \begin{align*}
            \begin{tabular}{l | r}
                \(T\) & \((x, y)\) \\
                \hline
                0 & (0,0) \\
                \(\pi / 6\) & \((1/2, \sqrt{3}/2)\) \\
                \(\pi / 4\) & \((\sqrt{2} / 2, 1)\) \\
                \(\pi / 3\) & \((\sqrt{3} / 2, \sqrt{3} / 2)\) \\
                \(\pi / 2\) & \((1, 0)\) 
            \end{tabular}
        \end{align*}
        By graphing these points, we can see the direction of travel is from 0 to 1 on the \(x\). 
        Then it goes into quadrant 4, back to the origin.
        It then travels into quadrant 2, then 3, then back to the origin.
    
\section{Calculus with parametric equations}
    Calculus of parametric equations lets us find the slope of the line at a certain point despite not being a function.
    The derivative of a function gives the slope of a curve at a point.
    Remember you can't take a derivative of a curve that isn't a function, it will return multiple values (fails the vertical line test).
    However, because we can define these curves as parametric equations, we can cut a piece of the curve out and use that as our function.
    Choose points on either side of the point \(P\) that we want to find the slope of. 
    We can then make a parametric equation to describe this function:
    \begin{align*}
        x = f(T) &&
        y = g(T) &&
        T \in  [a, b]
    \end{align*}
    Remember, our points are in terms of \(T\) so they take on the form:
    \[(x, y) = (f(T), g(T))\]
    The function starts at:
    \[(f(a), g(a))\]
    and ends at:
    \[(f(b), g(b))\]
    For the small section of the curve, our function, we can define \(y\) as a function of \(x\).
    \[y = F(x)\]
    Remember:
    \begin{align*}
        x = f(T) &&
        y = g(T)
    \end{align*}
    Substitute in our \(y\):
    \[g(T) = F(x)\]
    and substitue in our \(x\):
    \[g(T) = F(f(T))\]
    Now we can derive both sides (don't forget the chain rule):
    \[g'(T) = F'(f(T)) \cdot f'(T)\]
    We can substitute our \(x\) back in:
    \[g'(T) = F'(x) \cdot f'(T)\]
    So:
    \[F'(x) = \frac{g'(T)}{f'(T)}\]
    (This isn't a quotient rule! This is just a derivative over a derivative).
    This can be remembered by dividing the derivative of each function in terms of another variable (in this case \(T\)):
    \[\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{\frac{\mathrm{d}y}{\mathrm{d}T}}{\frac{\mathrm{d}x}{\mathrm{d}T}}\]
    
    \subsection{Example}
        Find the equation of the tangent line at \(T = \frac{\pi}{4}\):
        \begin{align*}
            x = \sec T &&
            y = \tan T &&
            - \frac{\pi}{2} < T < \frac{\pi}{2}
        \end{align*}
        Remember this curve isn't a function if it wraps around, so the tangent line is just local to the point.
        To write the equation of a line we need both a slope and a point. Lets find the point first:
        \begin{align*}
            T = \frac{\pi}{4} &&
            x = \sqrt{2} &&
            y = 1
        \end{align*}
        So we have the point \((\sqrt{2}, 1)\).
        Now to find the slope we need to find the derivative. Remember:
        \[\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{\frac{\mathrm{d}y}{\mathrm{d}T}}{\frac{\mathrm{d}x}{\mathrm{d}T}}\]
        So:
        \[\mathrm{d}y = \sec^2 T\]
        \[\mathrm{d}x = \sec T \tan T\]
        We can simplify them when we divide:
        \[\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{\sec^2 T}{\sec T \tan T}\]
        \[= \frac{\sec T}{\tan T}\]
        So lets plug in \(T\) and find the slope \(m\):
        \[m = \frac{\sec \pi / 4}{\tan \pi / 4}\]
        \[= \sqrt{2}\]
        Therefore we have the tangent line:
        \[y - 1 = \sqrt{2} (x - \sqrt{2})\]
    
    \subsection{Horizontal and vertical tangents}
        Starting with our idea of finding the slope at a point for a parametric equation:
        \[\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{\frac{\mathrm{d}y}{\mathrm{d}T}}{\frac{\mathrm{d}x}{\mathrm{d}T}}\] 
        
        \begin{itemize}
            \item Horizontal tangent lines (horizontal asymptotes) will occur when
            \begin{align*}
                \frac{\mathrm{d}y}{\mathrm{d}T} = 0 &&
                \frac{\mathrm{d}x}{\mathrm{d}T} \neq 0
            \end{align*}
            \item Vertical tangent lines (vertical asymptotes) occur when
            \begin{align*}
                \frac{\mathrm{d}y}{\mathrm{d}T} \neq 0 &&
                \frac{\mathrm{d}x}{\mathrm{d}T} = 0
            \end{align*}
        \end{itemize} 
    
    \subsection{Example}
        Find horizontal and veritcal tangents:
        \begin{align*}
            x = T^2 &&
            y = T^3 - 3T
        \end{align*}
        \begin{itemize}
            \item To check for horizontal tangents look for when \(\mathrm{d}y\) equals 0:
            \[\frac{\mathrm{d}y}{\mathrm{d}T} = 3T^2 - 3\]
            \[T = -1, 1\]
            So to find the two points where these horizontal tangents exist plug in each value of \(T\):
            \begin{align*}
                \text{When } T &\to 1 &&
                x = 1 &&
                y = 2 &&
                (1,2) \\
                \text{When } T &\to -1 &&
                x = 1 &&
                y = -2 &&
                (1,-2)
            \end{align*}
            \item To check for veritcal tangents look for when \(\mathrm{d}x\) equals 0:
            \[\frac{\mathrm{d}x}{\mathrm{d}T} = 2T\]
            \[T = 0\]
            So:
            \begin{align*}
                \text{When } T \to 0 &&
                x = 0 &&
                y = 0 &&
                (0,0)
            \end{align*}
        \end{itemize}
        Now we need to find \(x\) and \(y\) intercepts:
        \begin{itemize}
            \item \(x\) intercept:
            \[T^3 - 3T = 0\]
            \[T = 0, \pm \sqrt{3}\]
            Plugging these into our functions for \(x\) gives us these points:
            \begin{align*}
                (0, 0) &&
                (3, 0) &&
                (3, 0)
            \end{align*}
            This means that the path that the parametric curve takes must double back and hit the point \((3, 0)\) twice.
            \item \(y\) intercept:
            \[T^2 = 0\]
            \[T = 0\]
            So our point is:
            \[(0, 0)\]
        \end{itemize}
        
    \subsection{The second derivative}
        Starting with our idea of finding the slope at a point for a parametric equation:
        \[\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{\frac{\mathrm{d}y}{\mathrm{d}T}}{\frac{\mathrm{d}x}{\mathrm{d}T}}\]
        Start by taking a second derivative of this in terms of \(x\), remember \(x\) is a function of \(T\) so it will end up being in terms of \(T\).
        \[\frac{\mathrm{d}}{\mathrm{d}x} \left( \frac{\mathrm{d}y}{\mathrm{d}x} \right) = \frac{\mathrm{d}}{\mathrm{d}x} \left( \frac{\frac{\mathrm{d}y}{\mathrm{d}T}}{\frac{\mathrm{d}x}{\mathrm{d}T}} \right)\]
        \[\frac{\mathrm{d}^2 y}{\mathrm{d} x^2} = \frac{\frac{\mathrm{d}}{\mathrm{d}t} \left( \frac{\mathrm{d}y}{\mathrm{d}x} \right)}{\frac{\mathrm{d}x}{\mathrm{d}T}}\]
        So to find the second derivative we first find the first derivative, then the second, and divide by the derivative of \(x\) in terms of \(T\).
    
    \subsection{Example}
        Find the second derivative of:
        \begin{align*}
            x = T^2 - 4 &&
            y = T^3 - 3T
        \end{align*}
        So the first derivative is:
        \[\frac{\mathrm{d}y}{\mathrm{d}x} = \frac{3T^2 - 3}{2T}\]
        To take the second derivative make sure you use the quotient rule:
        \begin{align*}
            \frac{\mathrm{d}}{\mathrm{d}T} \left( \frac{\mathrm{d}y}{ \mathrm{d}x} \right) &= \frac{6T \cdot 2T - 2 (3T^2 - 3)}{4T^2} \\
            &= \frac{6T^2 + 6}{4T^2} \\
            &= \frac{3T^2 + 3}{2T^2}
        \end{align*}
        Then you divide by the derivative of \(x\) to get the second derivative of the parametric equation:
        \begin{align*}
            \frac{\mathrm{d}^2 y}{\mathrm{d} x^2} &= \frac{\frac{3T^2 + 3}{2T^2}}{2T} \\
            &= \frac{3T^2 + 3}{4T^3}
        \end{align*}
    
    \subsection{Finding length of parametric curves}
        Regarding the length of a curve:
        \[L = \int_a^b \sqrt{1 + (f'(x))^2} \mathrm{d}x\]
        In terms of a parametric equations, provided the part of the curve for which you are trying to find is "smooth" (no gaps, no sharp points),
        and doesn't not intersect itself, then the length can be found with:
        \[L = \int_a^b \sqrt{\left(\frac{\mathrm{d}x}{\mathrm{d}T}\right)^2 + \left(\frac{\mathrm{d}y}{\mathrm{d}T}\right)^2} \mathrm{d}T\]
        Remember the bounds \(a\) and \(b\) are in terms of \(T\).
    
    \subsection{Example}
        Find the length on the interval \(0 \leq T \leq 1\):
        \begin{align*}
            x = 2T^2 &&
            y = 3T^3
        \end{align*}
        So plug in to the length equation:
        \begin{align*}
            L &= \int_a^b \sqrt{\left(\frac{\mathrm{d}x}{\mathrm{d}T}\right)^2 + \left(\frac{\mathrm{d}y}{\mathrm{d}T}\right)^2} \mathrm{d}T \\
            && \text{Aside:} \\
            && \frac{\mathrm{d}x}{\mathrm{d}T} &= 4T \\
            && \frac{\mathrm{d}y}{\mathrm{d}T} &= 9T^2 \\
            &= \int_0^1 \sqrt{(4T)^2 + (9T^2)^2} \, \mathrm{d}T \\
            &= \int_0^1 \sqrt{16T^2 + 81T^4} \, \mathrm{d}T \\
            &= \int_0^1 T \sqrt{16 + 81T^2} \, \mathrm{d}T \\
            && \text{Let } u &= 16+ 81T^2 \\
            && \mathrm{d}u &= 162T \, \mathrm{d}T \\
            &= \frac{1}{162} \int \sqrt{u} \, \mathrm{d}u \\
            &= \frac{1}{162} \left[ \frac{2}{3} u^{3/2}\right] \\
            &= \frac{1}{243} \left[(16 + 81T^2)^{3/2} \right]_0^1 \\
            L &= \frac{1}{243} \left[ 97 \sqrt{97} - 4 \sqrt{4}\right] \\
        \end{align*}
    
    \subsection{Finding surface area of a parametric curve}
        Recall the surface area of a curve:
        \[S = \int_a^b 2 \pi f(x) \sqrt{1 + (f'(x)) ^2} \, \mathrm{d}x\]
        In terms of parametric equations:
        \begin{itemize}
            \item Regarding the length of a curve rotated around the x-axis (integrated with respect to \(x\)):
            \[S = \int_a^b 2 \pi y \sqrt{\left(\frac{\mathrm{d}x}{\mathrm{d}T}\right)^2 + \left(\frac{\mathrm{d}y}{\mathrm{d}T}\right)^2} \mathrm{d}T\]
            Note: \(y\) here is the height of the curve must be in terms of \(T\).
            \item Regarding the length of a curve rotated around the y-axis (integrating with respect to \(y\)):
            \[S = \int_a^b 2 \pi x \sqrt{\left(\frac{\mathrm{d}x}{\mathrm{d}T}\right)^2 + \left(\frac{\mathrm{d}y}{\mathrm{d}T}\right)^2} \mathrm{d}T\]
        \end{itemize}


\end{document}